
@article{cooper_harnessing_2024,
	title = {Harnessing large language models for coding, teaching and inclusion to empower research in ecology and evolution},
	volume = {15},
	issn = {2041-210X},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/2041-210X.14325},
	abstract = {{\textless}em{\textgreater}Methods in Ecology and Evolution{\textless}/em{\textgreater} is an open access journal publishing papers across a wide range of subdisciplines, disseminating new methods in ecology and evolution.},
	language = {en},
	number = {10},
	urldate = {2025-08-19},
	journal = {Methods in Ecology and Evolution},
	author = {Cooper, Natalie and Clark, Adam T. and Lecomte, Nicolas and Qiao, Huijie and Ellison, Aaron M.},
	month = oct,
	year = {2024},
	note = {Publisher: John Wiley \& Sons, Ltd},
	pages = {1757--1763},
}

@article{scheepens_large_2024,
	title = {Large language models help facilitate the automated synthesis of information on potential pest controllers},
	volume = {15},
	copyright = {© 2024 The Authors. Methods in Ecology and Evolution published by John Wiley \& Sons Ltd on behalf of British Ecological Society.},
	issn = {2041-210X},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/2041-210X.14341},
	doi = {10.1111/2041-210X.14341},
	abstract = {The body of ecological literature, which informs much of our knowledge of the global loss of biodiversity, has been experiencing rapid growth in recent decades. The increasing difficulty of synthesising this literature manually has simultaneously resulted in a growing demand for automated text mining methods. Within the domain of deep learning, large language models (LLMs) have been the subject of considerable attention in recent years due to great leaps in progress and a wide range of potential applications; however, quantitative investigation into their potential in ecology has so far been lacking. In this work, we analyse the ability of GPT-4 to extract information about invertebrate pests and pest controllers from abstracts of articles on biological pest control, using a bespoke, zero-shot prompt. Our results show that the performance of GPT-4 is highly competitive with other state-of-the-art tools used for taxonomic named entity recognition and geographic location extraction tasks. On a held-out test set, we show that species and geographic locations are extracted with F1-scores of 99.8\% and 95.3\%, respectively, and highlight that the model can effectively distinguish between ecological roles of interest such as predators, parasitoids and pests. Moreover, we demonstrate the model's ability to effectively extract and predict taxonomic information across various taxonomic ranks. However, we do report a small number of cases of fabricated information (confabulations). Due to a lack of specialised, pre-trained ecological language models, general-purpose LLMs may provide a promising way forward in ecology. Combined with tailored prompt engineering, such models can be employed for a wide range of text mining tasks in ecology, with the potential to greatly reduce time spent on manual screening and labelling of the literature.},
	language = {en},
	number = {7},
	urldate = {2025-08-28},
	journal = {Methods in Ecology and Evolution},
	author = {Scheepens, Daan and Millard, Joseph and Farrell, Maxwell and Newbold, Tim},
	year = {2024},
	note = {\_eprint: https://besjournals.onlinelibrary.wiley.com/doi/pdf/10.1111/2041-210X.14341},
	keywords = {ChatGPT, biocontrol, GPT-4, large language model, prompt engineering, relation extraction, taxonomic named entity recognition, text mining},
	pages = {1261--1273},
	file = {Full Text PDF:/Users/cjbrown0/Zotero/storage/Z6CXSAPW/Scheepens et al. - 2024 - Large language models help facilitate the automated synthesis of information on potential pest contr.pdf:application/pdf;Snapshot:/Users/cjbrown0/Zotero/storage/8BGFN2EG/2041-210X.html:text/html},
}

@article{laban_llms_2025,
	title = {Llms get lost in multi-turn conversation},
	journal = {arXiv preprint arXiv:2505.06120},
	author = {Laban, Philippe and Hayashi, Hiroaki and Zhou, Yingbo and Neville, Jennifer},
	year = {2025},
}

@article{zhu_are_2024,
	title = {Are {Large} {Language} {Models} {Good} {Statisticians}?},
	journal = {arXiv preprint arXiv:2406.07815},
	author = {Zhu, Yizhang and Du, Shiyin and Li, Boyan and Luo, Yuyu and Tang, Nan},
	year = {2024},
}

@article{gougherty_testing_2024,
	title = {Testing the reliability of an {AI}-based large language model to extract ecological information from the scientific literature},
	volume = {3},
	issn = {2731-4243},
	url = {https://doi.org/10.1038/s44185-024-00043-9},
	doi = {10.1038/s44185-024-00043-9},
	abstract = {Artificial intelligence-based large language models (LLMs) have the potential to substantially improve the efficiency and scale of ecological research, but their propensity for delivering incorrect information raises significant concern about their usefulness in their current state. Here, we formally test how quickly and accurately an LLM performs in comparison to a human reviewer when tasked with extracting various types of ecological data from the scientific literature. We found the LLM was able to extract relevant data over 50 times faster than the reviewer and had very high accuracy ({\textgreater}90\%) in extracting discrete and categorical data, but it performed poorly when extracting certain quantitative data. Our case study shows that LLMs offer great potential for generating large ecological databases at unprecedented speed and scale, but additional quality assurance steps are required to ensure data integrity.},
	number = {1},
	journal = {npj Biodiversity},
	author = {Gougherty, Andrew V. and Clipp, Hannah L.},
	month = may,
	year = {2024},
	pages = {13},
}

@article{jansen_leveraging_2025,
	title = {Leveraging large language models for data analysis automation},
	volume = {20},
	number = {2},
	journal = {PloS one},
	author = {Jansen, Jacqueline A and Manukyan, Artür and Al Khoury, Nour and Akalin, Altuna},
	year = {2025},
	note = {Publisher: Public Library of Science San Francisco, CA USA},
	pages = {e0317084},
}

@article{messeri_artificial_2024,
	title = {Artificial intelligence and illusions of understanding in scientific research},
	volume = {627},
	number = {8002},
	journal = {Nature},
	author = {Messeri, Lisa and Crockett, MJ},
	year = {2024},
	note = {Publisher: Nature Publishing Group UK London},
	pages = {49--58},
}

@article{le_conversational_2025,
	title = {A {Conversational} {Large}-{Language}-{Model} {Tutor} that {Accelerates} {Machine}-{Learning} {Method} {Development} in {Routine} {Bioanalytical} {Workflows}},
	volume = {n/a},
	copyright = {© 2025 The Author(s). ChemBioChem published by Wiley-VCH GmbH},
	issn = {1439-7633},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/cbic.202500678},
	doi = {10.1002/cbic.202500678},
	abstract = {As machine learning (ML) becomes increasingly relevant in experimental chemistry, many scientists face barriers to adoption due to limited training in ML. While AutoML platforms offer powerful capabilities, they lack the instructional scaffolding needed by users without an ML background. To address this gap, a lightweight, conversational assistant is presented that guides users through ML workflow design using plain-language dialog. Powered by OpenAI's GPT-4o and deployed via a Gradio interface, the assistant operates under a structured system prompt that simulates pedagogical reasoning. It behaves like a domain-specific tutor: helping users define ML goals, assess data structure, select models, evaluate metrics, and generate annotated Python code. A complete documentation of the development process is provided, allowing researchers to adapt the system for other domains. Herein, its utility is demonstrated in two representative case studies: 1) image classification of lateral flow immunoassay test strips for diagnostic readout; and 2) regression-based prediction of liquid chromatography–mass spectrometry retention times from molecular descriptors for small molecules. In both cases, lab members with no ML experience successfully developed working models guided solely by the assistant. By lowering the barrier to ML adoption in data-rich analytical workflows, this system offers a customizable workflow for building domain-specific assistants across experimental science.},
	language = {en},
	number = {n/a},
	urldate = {2025-10-05},
	journal = {ChemBioChem},
	author = {Le, An T. H. and Shvekher, Thomas and Nguyen, Lewis and Krylov, Sergey N.},
	year = {2025},
	note = {\_eprint: https://chemistry-europe.onlinelibrary.wiley.com/doi/pdf/10.1002/cbic.202500678},
	keywords = {prompt engineering, generative AI in biochemical science, machine learning education tool, machine learning in biochemical science, machine learning model design},
	pages = {e202500678},
	file = {Full Text PDF:/Users/cjbrown0/Zotero/storage/NMT8A37W/Le et al. - A Conversational Large-Language-Model Tutor that Accelerates Machine-Learning Method Development in.pdf:application/pdf;Snapshot:/Users/cjbrown0/Zotero/storage/4BH7SXGB/cbic.html:text/html},
}


@article{chen_unleashing_2025,
	title = {Unleashing the potential of prompt engineering for large language models},
	volume = {6},
	issn = {2666-3899},
	url = {https://www.cell.com/patterns/abstract/S2666-3899(25)00108-4},
	doi = {10.1016/j.patter.2025.101260},
	abstract = {{\textless}h2{\textgreater}Summary{\textless}/h2{\textgreater}{\textless}p{\textgreater}This review explores the role of prompt engineering in unleashing the capabilities of large language models (LLMs). Prompt engineering is the process of structuring inputs, and it has emerged as a crucial technique for maximizing the utility and accuracy of these models. Both foundational and advanced prompt engineering methodologies—including techniques such as self-consistency, chain of thought, and generated knowledge, which can significantly enhance the performance of models—are explored in this paper. Additionally, the prompt methods for vision language models (VLMs) are examined in detail. Prompt methods are evaluated with subjective and objective metrics, ensuring a robust analysis of their efficacy. Critical to this discussion is the role of prompt engineering in artificial intelligence (AI) security, particularly in terms of defending against adversarial attacks that exploit vulnerabilities in LLMs. Strategies for minimizing these risks and improving the robustness of models are thoroughly reviewed. Finally, we provide a perspective for future research and applications.{\textless}/p{\textgreater}},
	language = {English},
	number = {6},
	urldate = {2025-10-05},
	journal = {Patterns},
	author = {Chen, Banghao and Zhang, Zhaofeng and Langrené, Nicolas and Zhu, Shengxin},
	month = jun,
	year = {2025},
	note = {Publisher: Elsevier},
}

@article{connolly_improved_2021,
	author = {Connolly, R. M. and Fairclough, D. V. and Jinks, E. L. and Ditria, E. M. and Jackson, G. and Lopez-Marcano, S. and Olds, A. D. and Jinks, K. I.},
	title = {Improved Accuracy for Automated Counting of a Fish in Baited Underwater Videos for Stock Assessment},
	journal = {Frontiers in Marine Science},
	volume = {8},
	pages = {658135},
	year = {2021},
	doi = {10.3389/fmars.2021.658135}
}