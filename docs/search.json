[
  {
    "objectID": "04-llm-prompting-fundamentals.html",
    "href": "04-llm-prompting-fundamentals.html",
    "title": "4  LLM prompting fundamentals",
    "section": "",
    "text": "4.1 Setup authorisation\nGet your API key, see Section 3.4 and then Section 3.7 for connecting that to Ellmer.\nIf you are using Python, save your API key in a .env file in your project directory, like this: `OPENROUTER_API_KEY=my-key-here",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>LLM prompting fundamentals</span>"
    ]
  },
  {
    "objectID": "04-llm-prompting-fundamentals.html#understanding-how-llms-work",
    "href": "04-llm-prompting-fundamentals.html#understanding-how-llms-work",
    "title": "4  LLM prompting fundamentals",
    "section": "4.2 Understanding how LLMs work",
    "text": "4.2 Understanding how LLMs work\nLarge Language Models (LLMs) operate by predicting the next token in a sequence, one token at a time. To understand how this works in practice, we’ll call an API directly through computer code.\nBy accessing the API in this way we get as close to the raw LLM as we are able. Later on we will use ‘coding assistants’ (e.g. copilot) which put another layer of software between you and the LLM.\nTry to get it to complete a sentence:\n\nR - EllmerRPython\n\n\n\nlibrary(ellmer)\n\n# Initialize a chat with Claude\nchat &lt;- chat_openrouter(\n  system_prompt = \"\",\n  model = \"anthropic/claude-3.5-haiku\",\n  api_args = list(max_tokens = 50)\n)\nchat$chat(\"Ecologists like to eat \")\n\n\n\n\nlibrary(jsonlite)\nlibrary(httr)\nopenrouter_api_key &lt;- Sys.getenv(\"OPENROUTER_API_KEY\")\nresponse &lt;- POST(\n    url = \"https://openrouter.ai/api/v1/chat/completions\",\n    add_headers(\n      \"Content-Type\" = \"application/json\",\n      \"Authorization\" = paste(\"Bearer\", openrouter_api_key)\n    ),\n    body = toJSON(list(\n      model = \"anthropic/claude-3.5-haiku\",\n      messages = list(\n        list(\n          role = \"system\",\n          content = \"You are a helpful assistant.\"\n        ),  \n        list(\n          role = \"user\",\n          content = \"Ecologists like to eat \"\n        )\n      )\n    ), auto_unbox = TRUE),\n    encode = \"raw\"\n  )\nr3 &lt;- fromJSON(content(response, \"text\"))\nr3$choices$message$content\n\n\n\n\nimport requests\nimport json\nimport os\nfrom dotenv import load_dotenv\nload_dotenv()\n\napi_key = os.getenv(\"OPENROUTER_API_KEY\")\nmodel = \"anthropic/claude-3.5-haiku\"\nmessage = \"Ecologists like to eat \"\n\nresponse = requests.post(\n  url=\"https://openrouter.ai/api/v1/chat/completions\",\n  headers={\n    \"Authorization\": f\"Bearer {api_key}\",\n    \"Content-Type\": \"application/json\"\n  },\n  data=json.dumps({\n    \"model\": model,\n    \"messages\": [\n      {\n        \"role\": \"user\",\n        \"content\": message,\n      }\n    ]\n  })\n)\ndata = response.json()\ncontent = data['choices'][0]['message']['content']\n\n\n\n\nNotice that the model doesn’t do what we intend, which is complete the sentence. LLMs have a built in command to be an assistant. Let’s use the ‘system prompt’ to provide it with strong directions.\n\nTip: The system prompt sets the overall context for a chat. It is meant to be a stronger directive than the user prompt. In most chat interfaces (e.g. copilot) you are interacting with the user prompt. The provider has provided the system prompt, here’s the system prompt for the chat interface version of anthropic (Claude)\n\n\nR - EllmerRPython\n\n\n\nchat &lt;- chat_openrouter(\n  system_prompt = \"Complete the sentences the user providers you. Continue from where the user left off. Provide one answer only. Don't provide any explanation, don't reiterate the text the user provides\",\n  model = \"anthropic/claude-3.5-haiku\",\n  api_args = list(max_tokens = 50)\n)\nchat$chat(\"Ecologists like to eat \")\n\n\n\n\nlibrary(jsonlite)\nlibrary(httr)\nopenrouter_api_key &lt;- Sys.getenv(\"OPENROUTER_API_KEY\")\nresponse &lt;- POST(\n    url = \"https://openrouter.ai/api/v1/chat/completions\",\n    add_headers(\n      \"Content-Type\" = \"application/json\",\n      \"Authorization\" = paste(\"Bearer\", openrouter_api_key)\n    ),\n    body = toJSON(list(\n      model = \"anthropic/claude-3.5-haiku\",\n      messages = list(\n        list(\n          role = \"system\",\n          content = \"Complete the sentences the user providers you. Continue from where the user left off. Provide one answer only. Don't provide any explanation, don't reiterate the text the user provides\"\n        ),  \n        list(\n          role = \"user\",\n          content = \"Ecologists like to eat \"\n        )\n      )\n    ), auto_unbox = TRUE),\n    encode = \"raw\"\n  )\nr3 &lt;- fromJSON(content(response, \"text\"))\nr3$choices$message$content\n\n\n\n\nimport requests\nimport json\nimport os\nfrom dotenv import load_dotenv\nload_dotenv()\n\napi_key = os.getenv(\"OPENROUTER_API_KEY\")\nmodel = \"anthropic/claude-3.5-haiku\"\nmessage = \"Ecologists like to eat \"\nsystem_prompt = \"Complete the sentences the user providers you. Continue from where the user left off. Provide one answer only. Don't provide any explanation, don't reiterate the text the user provides\"\n\nresponse = requests.post(\n  url=\"https://openrouter.ai/api/v1/chat/completions\",\n  headers={\n    \"Authorization\": f\"Bearer {api_key}\",\n    \"Content-Type\": \"application/json\"\n  },\n  data=json.dumps({\n    \"model\": model,\n    \"messages\": [\n      {\n        \"role\": \"system\",\n        \"content\": system_prompt,\n      },\n      {\n        \"role\": \"user\",\n        \"content\": message,\n      }\n    ]\n  })\n)\ndata = response.json()\ncontent = data['choices'][0]['message']['content']\n\n\n\n\n\nTip: It is generally more effective to tell the LLM what to do rather than what not to do (just like people!).\n\n\n4.2.1 Temperature effects\nThe “temperature” parameter controls the randomness of token predictions. Lower temperatures (closer to 0) make the model more deterministic, while higher temperatures (closer to 2) make it more creative and unpredictable.\nLet’s compare responses with different temperatures:\n\n# Create chats with different temperature settings\nchat_temp &lt;- chat_openrouter(\n          system_prompt = \"Complete the sentences the user providers you. Continue from where the user left off. Provide one answer only. Don't provide any explanation, don't reiterate the text the user provides\",\n        model = \"anthropic/claude-3.5-haiku\",\n        api_args = list(max_tokens = 50, temperature = 0)\n    )\n\nchat_temp$chat(\"Marine ecologists like to eat \")\n\nchat_temp &lt;- chat_openrouter(\n          system_prompt = \"Complete the sentences the user providers you. Continue from where the user left off. Provide one answer only. Don't provide any explanation, don't reiterate the text the user provides\",\n        model = \"anthropic/claude-3.5-haiku\",\n        api_args = list(max_tokens = 50, temperature = 2)\n    )\n\nchat_temp$chat(\"Marine ecologists like to eat \")\n\nAt low temperatures, you’ll notice the model consistently produces similar “safe” completions that focus on the most probable next tokens. As temperature increases, the responses become more varied and potentially more creative, but possibly less coherent.\n\n\n4.2.2 Comparing model complexity\nDifferent models have different capabilities based on their size, training data, and architecture.\nFor example anthropic/claude-3.5-haiku has many fewer parameters than anthropic/claude-sonnet-4. This means that the latter model is more complex and can handle more nuanced tasks. However, haiku is significantly cheaper to run. Haiku is 80c per million input tokens vs $3 for Sonnet. Output tokens are $4 vs $15\nFor the kind of simple tasks we are doing here, both give similar results. We will compare models later in the workshop when we use github copilot.\n\n\n4.2.3 Understanding context windows\nLLMs have a limited “context window” - the amount of text they can consider when generating a response. This affects their ability to maintain coherence over long conversations. For most LLMs this is about 100-200K tokens, which includes input and output. However, Google’s models have up to 1 million tokens.\nWe’ll come back to the context window when we explore more advanced tools with longer prompts. These simple prompts don’t come close to using up the context window.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>LLM prompting fundamentals</span>"
    ]
  },
  {
    "objectID": "04-llm-prompting-fundamentals.html#improving-your-prompts",
    "href": "04-llm-prompting-fundamentals.html#improving-your-prompts",
    "title": "4  LLM prompting fundamentals",
    "section": "4.3 Improving your prompts",
    "text": "4.3 Improving your prompts\nTODO Insert some examples comparing with and without these approaches\n\n4.3.1 Being specific\n\n\n4.3.2 Giving context\nShowing data etc…\n\n\n4.3.3 Giving examples",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>LLM prompting fundamentals</span>"
    ]
  },
  {
    "objectID": "04-llm-prompting-fundamentals.html#diy-stats-bot",
    "href": "04-llm-prompting-fundamentals.html#diy-stats-bot",
    "title": "4  LLM prompting fundamentals",
    "section": "4.4 DIY stats bot",
    "text": "4.4 DIY stats bot\nLet’s put together what we’ve learnt so far and built our own chatbot. I’ve provided you with a detailed system prompt that implements a chat bot that specialises in helping with statistics. First, we read the bot markdown file from github, then we can use it in our chat session.\n\nR - EllmerRPython\n\n\n\nstats_bot &lt;- readr::read_file(url(\"https://raw.githubusercontent.com/cbrown5/R-llm-workshop/refs/heads/main/resources/DIY-stats-bot-system.md\"))\n\nchat_stats &lt;- chat_openrouter(\n  system_prompt = stats_bot,\n  model = \"anthropic/claude-sonnet-4\",\n  api_args = list(max_tokens = 5000)\n)\n\n\n\n\nlibrary(jsonlite)\nlibrary(httr)\nopenrouter_api_key &lt;- Sys.getenv(\"OPENROUTER_API_KEY\")\nstats_bot &lt;- readLines(\"https://raw.githubusercontent.com/cbrown5/R-llm-workshop/refs/heads/main/resources/DIY-stats-bot-system.md\")\nresponse &lt;- POST(\n    url = \"https://openrouter.ai/api/v1/chat/completions\",\n    add_headers(\n      \"Content-Type\" = \"application/json\",\n      \"Authorization\" = paste(\"Bearer\", openrouter_api_key)\n    ),\n    body = toJSON(list(\n      model = \"anthropic/claude-sonnet-4\",\n      messages = list(\n        list(\n          role = \"system\",\n          content = paste(stats_bot, collapse=\"\\n\")\n        ),\n        list(\n          role = \"user\",\n          content = \"Who are you?\"\n        )\n      ),\n      max_tokens = 5000\n    ), auto_unbox = TRUE),\n    encode = \"raw\"\n  )\nr3 &lt;- fromJSON(content(response, \"text\"))\nr3$choices$message$content\n\n\n\n\nimport requests\nimport json\nimport os\nfrom dotenv import load_dotenv\nload_dotenv()\n\napi_key = os.getenv(\"OPENROUTER_API_KEY\")\nmodel = \"anthropic/claude-sonnet-4\"\nimport requests\nstats_bot = requests.get(\"https://raw.githubusercontent.com/cbrown5/R-llm-workshop/refs/heads/main/resources/DIY-stats-bot-system.md\").text\n\nresponse = requests.post(\n  url=\"https://openrouter.ai/api/v1/chat/completions\",\n  headers={\n    \"Authorization\": f\"Bearer {api_key}\",\n    \"Content-Type\": \"application/json\"\n  },\n  data=json.dumps({\n    \"model\": model,\n    \"messages\": [\n      {\n        \"role\": \"system\",\n        \"content\": stats_bot,\n      },\n      {\n        \"role\": \"user\",\n        \"content\": \"Who are you?\",\n      }\n    ],\n    \"max_tokens\": 5000\n  })\n)\ndata = response.json()\ncontent = data['choices'][0]['message']['content']\n\n\n\n\n\nTip: How many of you started using “DIY-stats-bot-system.md” without first reading it? Did you find the easter egg in my prompt? For security you should ALWAYS read prompts before you start running them through LLM chats. We’ll see later that LLMs can be given ‘tools’ which allow them to run code on your computer. Its easy to see how a malicious prompt could mis-use these tools. We’ll cover security later.\n\n\n4.4.1 Improving the stats bot\nMake a local copy of the stats bot system prompt and try editing it. Try different commands within it and see how your chat bot responds (you’ll have to open a new chat object each time).\nHere’s some ideas.\n\nTry making a chat bot that is a verhment Bayesian that abhors frequentist statistics.\n\nYou could provide it with more mode-specific instructions. For instance, try to get the chatbot to suggest appropriate figures for verifying statistical models.\nTry different temperatures.\nAdd your own easter egg.\n\n\nTip: Adjectives, CAPITALS, *markdown* formatting can all help create emphasis so that your model more closely follows your commands. I used ‘abhors’ and ‘verhment’ above on purpose.\n\n\n\n4.4.2 Tools\nTools like Copilot Agent mode then go a step further and send the results of step 5 back to the LLM, which then interprets the results and the loop continues (sometimes with and sometimes without direct user approval).\nIf you want to go further with making your own tools, then I suggest you check out ellmer package. It supports tool creation in a structured way. For instance, I made a tool that allows an LLM to download and save ocean data to your computer.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>LLM prompting fundamentals</span>"
    ]
  },
  {
    "objectID": "04-llm-prompting-fundamentals.html#reflection-on-prompting-fundamentals",
    "href": "04-llm-prompting-fundamentals.html#reflection-on-prompting-fundamentals",
    "title": "4  LLM prompting fundamentals",
    "section": "4.5 Reflection on prompting fundamentals",
    "text": "4.5 Reflection on prompting fundamentals\nTo recap, the basic workflow an agent follows is:\n\nSet-up a system prompt with detailed instructions for how the LLM should format responses\nUser asks a question that is sent to the LLM\nLLM responds and sends response back to user\nSoftware on user’s computer attempts to parse and act on the response according to pre-determined rules\nUser’s computers enacts the commands in the response and provides results to user\n\nThe key things I hoped you learnt from this lesson are:\n\nBasic LLM jargon, including tokens, temperature, API access and different LLM models.\nSome different prompt strategies, including role prompting, emphasis, chain of thought and one-shot.\nThe fundamentals of tool use and agents.\n\nNow you understand the basics, let’s get into Github Copilot.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>LLM prompting fundamentals</span>"
    ]
  },
  {
    "objectID": "02-introduction.html",
    "href": "02-introduction.html",
    "title": "2  Introduction to LLMs for R",
    "section": "",
    "text": "Time: 9-10am\nIn this presentation I’ll cover how LLMs work, best practices prompt engineering, software, applications for R users and ethics.\nThis chapter provides an overview of:\n\nHow Large Language Models (LLMs) function and their capabilities\nBest practices for prompt engineering when working with R\nSoftware options available for R users to interact with LLMs (coding assistants)\nPractical applications of LLMs for R programming and data analysis\nEthical considerations when using LLMs for scientific work\n\nWe’ll explore how LLMs can enhance your R workflow, from code generation to data analysis assistance, while maintaining scientific rigor and reproducibility.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introduction to LLMs for R</span>"
    ]
  },
  {
    "objectID": "03-set-up.html",
    "href": "03-set-up.html",
    "title": "3  Software you’ll need for this book and how to set it up",
    "section": "",
    "text": "3.1 R packages\nIf you are using R then we will make use of: install.packages(c(\"vegan\", \"ellmer\",\"tidyverse\"). For Python users you can follow along most examples without these, this isn’t an R training course, its an course on using AI to assist with coding.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Software you'll need for this book and how to set it up</span>"
    ]
  },
  {
    "objectID": "03-set-up.html#options-for-ai-software",
    "href": "03-set-up.html#options-for-ai-software",
    "title": "3  Software you’ll need for this book and how to set it up",
    "section": "3.2 Options for AI software",
    "text": "3.2 Options for AI software\n\n3.2.1 Preferred option for R users\nWhat I will be using, and what I prefer you to use is:\n\nThe R program from the VS Code Integrated Development Environment (IDE)\nGithub Copilot\nR Ellmer package, for which you’ll need an API key to one of the LLM providers\n\nThe challenges with the above options are that it can sometimes be difficult to connect R and VScode. Comprehensive instructions are below. You may need IT help, especially if your computer is locked down!\nIf you chose this option you will need to follow instructions in this chapter for ‘Getting an API key’ (Section 3.4) (required for ellmer), ‘Ellmer set-up’ (Section 3.7), VS code setup (Section 3.5) and ‘Github Copilot set-up’ (Section 3.6).\n\n\n3.2.2 Option 2 for R users\nUse Rstudio with R. You will need ellmer and gander packages. See instructions below for ‘Getting an API key’ (Section 3.4), ‘Ellmer set-up’ (Section 3.7) and ‘Gander: Rstudio friendly alternative to copilot’ (Section 3.8).\nRstudio also has basic Github Copilot capablities. To use these (not essential for the workshop) get a copilot account (Section 3.6) then in Rstudio go to ‘Tools’ -&gt; ‘Global Options’ -&gt; ‘Copilot’ and enable it (follow instructions for entering password to setup).\n\n\n3.2.3 Python users\nI’m not a Python programmer, however, all the principles I’ll teach also apply to Python. You can easily follow on with the examples in Python.\nYou will need to have VSCode with Github Copilot. So I recommend you get the VScode software, then follow these instructions for Python set-up.\nThen follow the instructions for ‘Github Copilot set-up’ (Section 3.6).\nI also recommend you get an API key with OpenRouter (Section 3.4).\nYou don’t need an ellmer equivalent because most of the LLM providers already provide Python code on their webpages.\n\n\n3.2.4 Options 3 +\nThere are innumerable AI coding assistants now available. Feel free to BYO if you are using one that you are already comfortable with. However, I strongly recommend using a tool with IDE integration (meaning it can edit your R/Python scripts directly). See Section 3.9.\nAs a fall-back, you can follow this course via ChatGPT or Copilot, but it will lots of cutting and pasting. Not the integrated experience I want you to have.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Software you'll need for this book and how to set it up</span>"
    ]
  },
  {
    "objectID": "03-set-up.html#software-options-summary",
    "href": "03-set-up.html#software-options-summary",
    "title": "3  Software you’ll need for this book and how to set it up",
    "section": "3.3 Software options summary",
    "text": "3.3 Software options summary\nHere are some of the software options I’ve looked at. Or if you’ve picked your option from the above list, just jump ahead to the required sections.\n\n\n\n\n\n\n\n\n\nOption\nBest for\nPros\nCons\n\n\n\n\nVScode with Github Copilot\nCoders of all abilities who have a fixed budget or just want to try IDE integration\n- Subscription based- Capable free tier- Editor integration (auto-complete style)- Agent mode- Multiple LLMs available- Easy to use\n- VSCode can be hard to set-up for R users- Less flexibility and customization than other agents- The Github Copilot Agent is less automated than other agent software- Limited choice of LLMs (unless you BYO API key)\n\n\nEllmer R package\nR users who want to create their own chat bots, or integrate LLMs into their code and shiny apps. For example, to extract data from a large corpus of papers.\n- Works anywhere R works- Unlimited flexibility- BYO API key, can interact with any LLM- Automate API calls to LLMs\n- Only a basic prompt interface provided (you need to write it)\n\n\nGander R package\nModerately experienced R users who don’t want to leave RStudio.\n- Works with Rstudio- Can see ‘inside of’ R objects, so knows your variable names- Can customize how it works to optimize performance and cost- BYO API key, can interact with any LLM\n- Requires some experience with the R program- Not as deeply integrated with Rstudio as Github Copilot is with VScode (doesn’t have as many features as copilot)\n\n\nAider\nExperienced python programmers\n- Python based AI agent- Interact with the agent via Python code- Highly flexible, can use as an everyday coding assistant or to create bespoke agents- Can edit files as well as run in agent mode\n- Not a straightforward prompt interface- Requires Python coding experience\n\n\nVSCode with Roo Code\nExperienced programmers who want to fully automate coding workflows\n- Fully automated agents- Multiple modes for different behaviours, e.g. architect versus code- Orchestrate mode that can delegate to sub-agents and complete very complex tasks- BYO API key- System messages fully customizable for advanced scientific applications of agents- One of the best performing and most popular agents\n- VSCode can be hard to set-up for R users- Can get more expensive- Does not do inline code editing ‘as you type’ like copilot- Not suitable for novice programmers\n\n\nVSCode with Cline\nSame as Roo Code. The user base for Cline is slightly larger.\n- Fully automated agents- Multiple modes for different behaviours- BYO API key- System messages customizable- Large user base\n- Less options for customizing the system prompt compared to Roo Code- Not suitable for novice programmers\n\n\nPositron with Roo Code or Cline\nR users who don’t want to use VScode. Positron is a fork (copy) of VScode managed by Posit, the group who run RStudio.\n- Possibly a bit easier to set-up R than with VScode- Pros and cons are same as VScode with Roo Code or Cline\n- New software- Limited features and support\n\n\n\nThere are many other (10s, 100s?) of coding assistants now available. Some prominent examples are Claude code, Cursor and Windsurf. I haven’t tried these, I understand they are similar to Github Copilot. Last time I checked none of them worked with Rstudio.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Software you'll need for this book and how to set it up</span>"
    ]
  },
  {
    "objectID": "03-set-up.html#sec-apikeys",
    "href": "03-set-up.html#sec-apikeys",
    "title": "3  Software you’ll need for this book and how to set it up",
    "section": "3.4 Getting an API key",
    "text": "3.4 Getting an API key\nAn API key is like a password that allows the AI assistant (e.g. roo code) to send your prompt to a large language model. Your key should be kept private. Usually you’ll have to buy some credits. These allow you to send prompts to the LLM. You’ll be paying per prompt.\nNow you need to choose your large language model provider. I’m currently using OpenRouter and Anthropic, which have a diversity of models for generating text, code and reading images. Do some web searching to find out the latest info on providers and models.\nYou choose depends on what you want to do and your budget. Some providers offer a free tier. You’ll need to web search for the latest info on this.\nFor this workshop I strongly recommend you get an OpenRouter API key. This will give you the most flexibility to try different models and to find models that have free options.\nOnce you’ve chosen a provider, create an account and follow their instructions for creating an API key. You will probably also need to buy some credit to use the model.\nThe one caveat is that OpenRouter may not have access the the full capabilities of all LLMs. For example, when Sonnet 3.7 came out you could get vision capabilities via an Anthropic API key but not with an OpenRouter API key.\nImportant the sign-up for getting an API key is often through a different webpage to the sign-up you may be using for subscription based AI tools (e.g. Claude Code or ChatGPT). Here are a couple of key links:\n\nSign-up here to get an API key for OpenRouter to access LLMs from 100s of providers\nSign-up here to get an API key for Anthropic’s LLMs\nSign-up here to get an API key for OpenAI’s LLMs",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Software you'll need for this book and how to set it up</span>"
    ]
  },
  {
    "objectID": "03-set-up.html#sec-vscodesetup",
    "href": "03-set-up.html#sec-vscodesetup",
    "title": "3  Software you’ll need for this book and how to set it up",
    "section": "3.5 VSCode set-up for R users",
    "text": "3.5 VSCode set-up for R users\nVScode has many extensions that let you create and run entire workflows via using prompts to a large language model. Its not widely used in the R community yet, but I expect it will be soon. You can create your entire R project, interpret the results and write a draft of your findings without writing any R code.\nMost of these tools are not available (as of writing) in RStudio, or have only limited functionality. So you need to use a different IDE (Integrated Development Environment) to run your R code. Here I’ll explain how to set-up VSCode (a popular IDE) so you can use Cline.\n\n3.5.1 Software requirements\nTo set up VScode for R and Cline, you’ll need:\n\nR programming language\nVScode text editor\nR extension for VScode\nCline AI assistant extension for VScode\n\nNote that if you computer is controlled centrally by an IT department, you may need to request admin access to install software, or email IT and ask for them to come and help you.\n\n\n3.5.2 Install R\n\nGo to the official R project website: https://www.r-project.org/\nClick the “download R” link in the Getting Started section\nChoose a CRAN mirror close to your location\nDownload the appropriate R installer for your operating system\nRun the installer and follow the prompts to complete installation\n\n\n\n3.5.3 R packages\n\nOpen R or RStudio\nInstall language server install.packages(\"languageserver\")\nInstall httpgd install.packages(\"httpgd\") (this helps improve plots in VScode). NOTE that httpgd seems to often be removed from CRAN, then come back again, I’m not sure why… If you are having trouble you can try install from a different repo, see instructions here: https://community.r-multiverse.org/httpgd\n\n\n\n3.5.4 Install VScode\n\nGo to the official VScode website: https://code.visualstudio.com/\nClick the big blue “Download” button\nDownload the appropriate VScode installer for your operating system\nRun the installer and follow the prompts\nLaunch VScode once installation is complete\n\n\n\n3.5.5 Install R extension\n\nOpen VScode\nOpen the Extensions view in VScode (click the boxes on left hand side)\nSearch for “R” in the extensions marketplace\nSelect the “R” extension published by REditorSupport\nClick the “Install” button\nRestart VScode after installation if prompted\n\nMore info on vscode and R here\n\n\n3.5.6 Connect R and VScode\n\nOpen a new terminal in VScode (Terminal &gt; New Terminal)\nCheck that R is installed by running: R --version\nType R to open the R console in the terminal\nNow open any R script in VS code (File &gt; Open)\nRun some R code to check that VS code can connect to R in the terminal. Use the shortcut Ctrl+Enter/Cmd+Enter or press the play button in the top right of the script editor.\n\nIf R is not found then open extensions (left hand side, boxes icon), filter by ‘enabled’ then click the R extension. Now click the cog icon in the R extension and select ‘settings’ from the dropdown. Search for ‘rpath’. Check that it has the correct path to R on your computer. You can find the path by opening a terminal and typing which R (on mac) or in a windows terminal where R.\nWhile you have the extension settings open search for ‘httgp’ and make sure Plot: Use Httpgd is enabled.\n\n\n3.5.7 Issues and tips for VScode with R\nThis is just a list of issues I’ve had and how I’ve solved them.\nPlotting If your R plots look weird (like tiny font), make sure httpgp is enabled. Go back to steps above and see how to do that.\nViewing data There are various extensions for viewing csv and excel files. It is worth looking into these so that when you do View(dat) in R you get a nice table. Some also allow editing.\nGetting help to install software My computer is somewhat locked down by IT, so getting this set-up was a bit fiddly and required a few requests to IT to install software.\nR markdown There are options in the R extension settings for how to knit markdown. You may need to configure these if you want to knit markdown docs from VScode. If you are having trouble knitting markdown it may mean that the path to pandoc is not set correctly. There is some helpful instructions here\nR terminal crashes If I run too much R code at once (like selecting a big block then running) the terminal tends to crash. Initially I see a little highlighted box saying ‘PTY HOST’. Then I need to close all the terminals (with the bin icon) and start again. Try radian if this is a problem. You can also code run line-by-line or source whole scripts from the terminal (which works fine). I tried debugging this by increasing the buffer but to on avail.\nShortcut keys (on osx) cmd-/ to comment uncomment lines. cmd-shift-p to open the command palette, cmd-b to open the file explorer, cmd-enter to run lines or selection of R code, cmd-shift-c to open terminal in new window, cntrl-shift-` to open a new terminal in vs code.\n\n\n3.5.8 Installing radian (optional)\nRadian is a terminal editor that is a bit nicer than the base R one. It does autocomplete in the terminal (like Rstudio does in the console), colours code/brackets etc… and allows multi-line editing in the terminal.\nTo set this up, install radian (you need python to do this). More instructions here.\nThen go to the terminal and find the path where radian is installed (e.g. which radian on mac or where radian on windows).\nNow open your settings in VScode (cmd-,) and search for ‘rterm’ (stands for ‘R Terminal’, don’t change the rpath which we set just before). Add the path to radian to the rterm setting. Also search for the setting ‘R: Bracketed Paste’ and make sure it is enabled.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Software you'll need for this book and how to set it up</span>"
    ]
  },
  {
    "objectID": "03-set-up.html#sec-githubcopilot",
    "href": "03-set-up.html#sec-githubcopilot",
    "title": "3  Software you’ll need for this book and how to set it up",
    "section": "3.6 Github Copilot set-up",
    "text": "3.6 Github Copilot set-up\nOnce you have VSCode just follow the simple steps here. Note if you already have a Github account make sure you have your login information handy.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Software you'll need for this book and how to set it up</span>"
    ]
  },
  {
    "objectID": "03-set-up.html#sec-ellmer",
    "href": "03-set-up.html#sec-ellmer",
    "title": "3  Software you’ll need for this book and how to set it up",
    "section": "3.7 Ellmer set-up",
    "text": "3.7 Ellmer set-up\nFirst, you need to get an API key from the provider, see step above on ‘Getting an API key’.\nThen, you need to add the key to your .Renviron file:\nusethis::edit_r_environ()\nThen type in your key like this:\nOPENROUTER_API_KEY=“xxxxxx”\nIf you are using open AI it would be like this:\nOPENAI_API_KEY=“xxxxxx”\ni.e. use the appropriate name for the provider you are using.\nThen restart R. ellmer will automatically find your key so long as you use the recommended environment variable names. See ?ellmer::chat_openrouter (or chat_xxx where xxx is whatever provider you are using).",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Software you'll need for this book and how to set it up</span>"
    ]
  },
  {
    "objectID": "03-set-up.html#sec-gander",
    "href": "03-set-up.html#sec-gander",
    "title": "3  Software you’ll need for this book and how to set it up",
    "section": "3.8 Gander: Rstudio friendly alternative to copilot",
    "text": "3.8 Gander: Rstudio friendly alternative to copilot\nGander lets you select code in Rstudio and edit it directly through calls to an LLM.\nFollow the steps to set-up Ellmer first.\nThen you can install.packages(gander)\nNow, you need to do two steps before Gander will work. First you need to add your default LLM to the .Rprofile so Gander knows what LLM to use type: usethis::edit_r_profile()\nNow set the option for your LLM, e.g. \noptions(.gander_chat = ellmer::chat_anthropic()) or options(.gander_chat = ellmer::chat_openai())\nNow add a keyboard short-cut to use Gander. Go to the ‘Tools’ menu at the top, click ‘Add-ins’, ‘Browse Add-ins’, then click the ‘Keyboard shortcuts’ button. Find the row for Gander (probably at the bottom), click in the second column for ‘Shortcut’ and type your keyboard shortcut. I used cmd-i (or cntrl-i). Then click ‘Cancel’ once you’ve set the shortcut key (‘Cancel’ as we don’t want to run Gander right now).\nIf for some reason the shortcut key won’t you can also gander::gander_addin() at anytime from R.\nNow to check it works, open an R project and select a line of R code. Press your shortcut keys. A box should pop up. Type a prompt (like ‘make this code more fun’) and hit enter to test it does something.\nI recommend reading the gander reference as there are ways you can customize it to know your data but also save on tokens.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Software you'll need for this book and how to set it up</span>"
    ]
  },
  {
    "objectID": "03-set-up.html#sec-otheroptions",
    "href": "03-set-up.html#sec-otheroptions",
    "title": "3  Software you’ll need for this book and how to set it up",
    "section": "3.9 Installing other gen AI VSCode extensions",
    "text": "3.9 Installing other gen AI VSCode extensions\ne.g. if you want to try Roo Code or Cline.\n\nOpen the Extensions view in VScode (Ctrl+Shift+X)\nSearch for the genAI assistant of your choice. I’m use Roo Code currently. Cline is another popular choice.\nSelect the extension\nClick the “Install” button\nThe extension icon (e.g. a Roo if using Roo Code) should appear in the VScode sidebar (left side).\n\nYou’ll have to navigate the extensions menus to input your API key. It won’t work without an API key that gives you access to an LLM. e.g. for Roo Code:\n\nClick on the extension icon (e.g. a roo for roo code or robot for cline) on the left hand side\nClick the cog (if the settings don’t open automatically)\nSelect your API provider and cut and paste the API key into the box.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Software you'll need for this book and how to set it up</span>"
    ]
  },
  {
    "objectID": "05-research-applications-LLMs.html",
    "href": "05-research-applications-LLMs.html",
    "title": "5  Research applications of LLMs",
    "section": "",
    "text": "5.1 Automating literature reviews",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Research applications of LLMs</span>"
    ]
  },
  {
    "objectID": "05-research-applications-LLMs.html#deep-research",
    "href": "05-research-applications-LLMs.html#deep-research",
    "title": "5  Research applications of LLMs",
    "section": "5.2 Deep research",
    "text": "5.2 Deep research\nRun through how to get code off of github https://github.com/cbrown5/web-search-ai\n\nlibrary(httr)\nlibrary(jsonlite)\n\nsource(\"perplexity-search-functions.R\")\n\nopenrouter_api_key &lt;- Sys.getenv(\"OPENROUTER_API_KEY\")\n\n# Example of standard web search query\n\nif (FALSE) {\nuser_message &lt;- \"What types of biases occur in fisheries stock models?\"\n\nsystem_message &lt;- \"You are a helpful AI assistant. \n        Rules: \n        1 Include the DOI in your report of any paper you reference.   \n        2. Produce reports that are less than 10000 words.\"\n\n}\n\n# Example of generating an R tutorial \n\nif (TRUE){\n\nuser_message &lt;- \"How can I relate multiple ecological response variables for benthic cover to an environmental gradient in the R program?\"\n\nsystem_message &lt;- \"You are a helpful AI agent who creates statistical analysis tutorials in R. \n        Rules: \n        1. Include text and examples of code in your responses. \n        2. Produce reports that are less than 10000 words.\"\n}\n\n\nresponse &lt;- call_openrouter_api(\n  openrouter_api_key,\n  model = \"perplexity/sonar-deep-research\",\n  system_message = system_message,\n  user_message,\n  search_context_size = \"medium\"\n  #Options \"low\"  \"medium\", \"high\"\n)\n\n# Example usage:\nsave_response_as_qmd(response, \"results/results.qmd\")",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Research applications of LLMs</span>"
    ]
  },
  {
    "objectID": "05-research-applications-LLMs.html#image-analysis",
    "href": "05-research-applications-LLMs.html#image-analysis",
    "title": "5  Research applications of LLMs",
    "section": "5.3 Image analysis",
    "text": "5.3 Image analysis",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Research applications of LLMs</span>"
    ]
  },
  {
    "objectID": "06-github-copilot.html",
    "href": "06-github-copilot.html",
    "title": "6  Github copilot for R",
    "section": "",
    "text": "6.1 Inline code editing\nThis chapter explores techniques for using GitHub Copilot’s inline code editing capabilities to enhance your R programming workflow.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Github copilot for R</span>"
    ]
  },
  {
    "objectID": "07-specification-sheets.html",
    "href": "07-specification-sheets.html",
    "title": "7  Best practices project setup",
    "section": "",
    "text": "7.1 Project organization\nIts helpful to set-up your projects in an organized and modularised way. In my experience most R users write most of their analysis in one long script. Don’t do this. It will be hard for ‘future you’ to navigate. If its hard for a human to navigate, it will also be hard for the assistant. Here’s how I set-up my projects.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Best practices project setup</span>"
    ]
  },
  {
    "objectID": "07-specification-sheets.html#project-organization",
    "href": "07-specification-sheets.html#project-organization",
    "title": "7  Best practices project setup",
    "section": "",
    "text": "7.1.1 General guidance\n\nCreate a new folder for each new project.\nOptional but recommended: Initiliaze a git repo in that folder (I use github desktop).\nSet-up folders and files in an organized way\nIdeally put the data in this folder also. However, large datasets or sensitive data can be kept in other folders.\nKeep scripts short and modularized (e.g one for data analysis, one for modelling).\n\nOnce you have your folder you can make it an Rstudio project (if using Rstudio) or just use ‘open folder’ in vscode. If want to link multiple folders in then use VScode workspaces.\nIf you are not using git (version control), then I recommend you learn. LLM code editing tools can cause you to lose older versions. So best to back them up with proper use of git.\n\n\n7.1.2 Project directory structure example\nHere’s an example of a project directory structure. You don’t have to use this strucutre. the important thing is to be organized.\nmy-project/\n├── README.md \n├── .gitignore\n├── Scripts/ # R code\n│   ├── 01_data-prep.R\n│   ├── 02_data-analysis.R\n│   └── 03_plots.R\n├── Shared/       \n│   ├── Outputs/\n│   │   ├── Figures/\n│   │   ├── data-prep/\n│   │   └── model-objects/\n│   ├── Data/\n│   └── Manuscripts/   \n└── Private/",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Best practices project setup</span>"
    ]
  },
  {
    "objectID": "07-specification-sheets.html#the-readme.md-file",
    "href": "07-specification-sheets.html#the-readme.md-file",
    "title": "7  Best practices project setup",
    "section": "7.2 The README.md file",
    "text": "7.2 The README.md file\nThe README.md is the memory for the project. If you use github it will also be the landing page for your repo, which is handy.\nRemember you are writing this for you and the LLMs. So think of it like a prompt.\nHere’s an example of some of the information you might want to include in your readme.\n# PROJECT TITLE\n\n## Summary\n\n## Aims\n\n## Data methodology\n\n## Analysis methodology\n\n## Tech context\n- We will use the R program\n- tidyverse packages for data manipulation\n- ggplot2 for data visualization\n\nKeep your scripts short and modular to facilitate debugging. Don't complete all of the steps below in one script. Finish scripts where it makes sense and save intermediate datasets. \n\n## Steps\nAs you go tick of the steps below. \n\n[ ] Wrangle data\n[ ] Fit regression\n[ ] Plot verification\n[ ] ... \n\n## Data \n\nInclude meta-data here and file paths. \n\n## Directory structure \n\nmy-project/\n├── README.md \n├── .gitignore\n├── Scripts/ # R code\n│   ├── 01_data-prep.R\n│   ├── 02_data-analysis.R\n│   └── 03_plots.R\n├── Shared/       \n│   ├── Outputs/\n│   │   ├── Figures/\n│   │   ├── data-prep/\n│   │   └── model-objects/\n│   ├── Data/\n│   └── Manuscripts/   \n└── Private/",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Best practices project setup</span>"
    ]
  },
  {
    "objectID": "07-specification-sheets.html#example-data",
    "href": "07-specification-sheets.html#example-data",
    "title": "7  Best practices project setup",
    "section": "7.3 Example data",
    "text": "7.3 Example data\nFor the next few chapters we’ll work with some ecological data on benthic marine habitats and fish.\n\n7.3.1 Case-study: Bumphead parrotfish, ‘Topa’ in Solomon Islands\nBumphead parrotfish (Bolbometopon muricatum) are an enignmatic tropical fish species. Adults of these species are characterized by a large bump on their forehead that males use to display and fight during breeding. Sex determination for this species is unknown, but it is likely that an individual has the potential to develop into either a male or female at maturity.\nAdults travel in schools and consume algae by biting off chunks of coral and in the process they literally poo out clean sand. Because of their large size, schooling habit and late age at maturity they are susceptible to overfishing, and many populations are in decline.\nTheir lifecycle is characterized by migration from lagoonal reef as juveniles (see image below) to reef flat and exposed reef habitats as adults. Early stage juveniles are carnivorous and feed on zooplankton, and then transform into herbivores at a young age.\n\nImage: Lifecycle of bumphead parrotfish. Image by E. Stump and sourced from Hamilton et al. 2017.\nUntil the mid 2010s the habitat for settling postlarvae and juveniles was a mystery. However, the pattern of migrating from inshore to offshore over their known lifecycle suggests that the earliest benthic lifestages (‘recruits’) stages may occur on nearshore reef habitats.\nNearshore reef habitats are susceptible to degradation from poor water quality, raising concerns that this species may also be in decline because of pollution. But the gap in data from the earliest lifestages hinders further exploration of this issue.\nIn this course we’ll be analyzing the first survey that revealed the habitat preferences of early juveniles stages of bumphead parrotfish. These data were analyzed by Hamilton et al. 2017 and Brown and Hamilton 2018.\nIn the 2010s Rick Hamilton (The Nature Conservancy) lead a series of surveys in the nearshore reef habitats of Kia province, Solomon Islands. The aim was to look for the recruitment habitat for juvenile bumphead parrotfish. These surveys were motivated by concern from local communities in Kia that topa (the local name for bumpheads) are in decline.\nIn the surveys, divers swam standardized transects and searched for juvenile bumphead in nearshore habitats, often along the edge of mangroves. All together they surveyed 49 sites across Kia.\nThese surveys were made all the more challenging by the occurrence of crocodiles in mangrove habitat in the region. So these data are incredibly valuable.\nLogging in the Kia region has caused water quality issues that may impact nearshore coral habitats. During logging, logs are transported from the land onto barges at ‘log ponds’. A log pond is an area of mangroves that is bulldozed to enable transfer of logs to barges. As you can imagine, logponds are very muddy. This damage creates significant sediment runoff which can smother and kill coral habitats.\nRick and the team surveyed reefs near logponds and in areas that had no logging. They only ever found bumphead recruits hiding in branching coral species.\nIn this course we will first ask if the occurrence of bumphead recruits is related to the cover of branching coral species. We will then develop a statistical model to analyse the relationship between pollution from logponds and bumphead recruits, and use this model to predict pollution impacts to bumpheads across the Kia region.\nThe data and code for the original analyses are available at my github site. In this course we will use simplified versions of the original data. We’re grateful to Rick Hamilton for providing the data for this course.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Best practices project setup</span>"
    ]
  },
  {
    "objectID": "08-advanced-llm-agents.html",
    "href": "08-advanced-llm-agents.html",
    "title": "8  Advanced LLM agents",
    "section": "",
    "text": "Time: 3:00-3:30pm\nSoftware requirements: VScode with R, Roo code, API license.\nWe’ll take a quick look at Roo Code and its customization options.\nRoo code is more complex and expensive to use than copilot, but allows significant amounts of customization to make bespoke agents that can help with the scientific process.\nI’ll use an example with the Benthic Data analysis (benthic-readme.md).\nTalk through:\n\nAPI access\nModel options\nCustomizing system message\nContext window management\nCost\nVision capabilities",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Advanced LLM agents</span>"
    ]
  },
  {
    "objectID": "09-ethics-copyright.html",
    "href": "09-ethics-copyright.html",
    "title": "9  Ethics and copyright",
    "section": "",
    "text": "9.1 Impacts on learning\nDoes AI make our brains lazy? One study found less engagement and deep thinking for students who had access to chatGPT for writing an essay compared to students who just had web searches or had no internet connectivity.\nI think the upshot is using it deliberatley and being careful not to replace your own creativity.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Ethics and copyright</span>"
    ]
  },
  {
    "objectID": "09-ethics-copyright.html#sustainability",
    "href": "09-ethics-copyright.html#sustainability",
    "title": "9  Ethics and copyright",
    "section": "9.2 Sustainability",
    "text": "9.2 Sustainability\nTraining LLMs costs millions of dollars, much of this cost is energy use. Further, the data centres for training and running LLMs need water for cooling. Asking a finished LLM questions uses much less energy, but cumulatively across the globe it adds up to a lot. Here are a few informative statistics I found online:\nFrom Forbes:\n\n“ChatGPT’s daily power usage is nearly equal to 180,000 U.S. households, each using about twenty-nine kilowatts.”\nMicrosoft emissions have risen 30% since 2020 due to data centers\nAI prompts use 10x more energy than a traditional google search\n\nTo put it in context I did some calculations on my personal usage. I estimate the prompting I do through copilot each year will cost about 2.32 kg of C02 and about 1000 litres of water. (this is lower bound, as I also using LLMs for other tasks).\nTo put that in context, flying the 1.5 hours from Halifax to Montreal is about 172kg of emissions, driving 15 minutes is about 3 kg. So I’m using approximately 10 less than a short flight, or the same as driving to work once. 1000L is equivalent to taking about 22 5-minute showers.\nOf course, the carbon cost is global, whereas the water cost is localised (Probably to US data centres, so by using this resource I’m really just making the water problem worse for Americans. )\nSo its not a huge increase in my personal energy use. But cumulatively across the globe it is a lot.\nMore generally, humanities energy use is growing exponential. Despite renewables and so on, ultimately our planet won’t be able to sustain this energy drawdown. LLMs are part of that trend of growing energy use. At some point we need to start using less energy, or the biosphere will become depleted and return to a ‘moon like rock’ in one study’s words.\nHere’s my personal belief.\nIf we’re smart humanity will use this technology to find ways to make our use of the planet more sustainable and ultimately save water and energy. Just like we should have been using fossil fuels to develop a transition to lasting sustainanle energy use. So you can guess how likely that is to happen…\nIts the reason I’m teaching this course. I don’t personally think that LLMs make our lives better, or humanity more sustainable. They just raise the bar on the rate of progress.\nYou can bet industries are using this technology to improve their productivity (= greater environmental impacts). I believe as environmental scientists we need to try to keep up. Ultimately we need progress on local to planetary sustainability (environmental scientists) to outpace the development of the industries that are environmentally unsustainable.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Ethics and copyright</span>"
    ]
  },
  {
    "objectID": "09-ethics-copyright.html#model-biases",
    "href": "09-ethics-copyright.html#model-biases",
    "title": "9  Ethics and copyright",
    "section": "9.3 Model biases",
    "text": "9.3 Model biases\nThis is a big one. I recommend everyone read this perspective on the ‘Illusion of Understanding’\nIts important that we don’t become too reliant on AI for our work. That’s why I’m teaching and promoting thoughtful use.\nSome key points:\n\nWe need to maintain and grow research fields that aren’t convenient to do with AI, not just grow the stuff that’s easy with AI\nWe need to push ourselves as individuals to not ‘be lazy’ and rely on AI too much. There is still great value in human learning. This requires mental energy, for instance, you will know something better if you write it yourself rather than write it with AI.\nWe need to be aware of biases in the content AI generates\n\nFor statistics these biases are likely to be a preference for well-known methods developed by Western science. So you should still read the literature broadly and avoid using AI, or prompt it in different ways, if you truly want to create novel statitistics (as opposed to using it to do statistics on a study that is otherwise novel data etc…)",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Ethics and copyright</span>"
    ]
  },
  {
    "objectID": "09-ethics-copyright.html#rising-inequality",
    "href": "09-ethics-copyright.html#rising-inequality",
    "title": "9  Ethics and copyright",
    "section": "9.4 Rising inequality",
    "text": "9.4 Rising inequality\nAI development is currently concentrated in the USA and profits for LLM use go to American companies. (USA is itself a country with massive inequality issues!). So the extent to LLMs replaces labour will redirect income and taxes from jobs in countries to American companies.\nIt is likely that the current low cost of LLM use will not continue. Companies are running at a loss in order to gain market share. So be careful how dependent you become on the LLMs and what that budget is replacing in your research budgets.\nI personally beleive that our own countries should be developing our own LLM products and resources. Even if they are not ‘industry leading’ they can still be highly effective for specific tasks. There are open-source models available that can fill this role.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Ethics and copyright</span>"
    ]
  },
  {
    "objectID": "09-ethics-copyright.html#copyright",
    "href": "09-ethics-copyright.html#copyright",
    "title": "9  Ethics and copyright",
    "section": "9.5 Copyright",
    "text": "9.5 Copyright\nMany LLMs have been trained on pirated books. The extent to which this is recognized by law is still in court.\nFor me personally its frustrating that I spent years developing a statistics blog (which was open-access, but I appreciated attribution), but now that information has been mined by LLMs. Thus AI companies are profiting from our collective knowledge.\nIt is an even worse situation for authors who’s livelihoods and careers depend on their copyrighted works.\nCopilot does in theory block itself from writing code that might be copyrighted. However, the efficacy of this system is unclear (it seems to just be a command in the system prompt). So be careful. Here are some recommendations for individuals\n\nIn general you own works you create with an LLM.\nThis also means you have the liability for any works you create (not normally an issue in environmental sciences).\ne.g. you couldn’t blame the LLM if you had to retract a paper due to incorrect statistics.\nYou should acknolwedge LLM use in academic publications, and what you used it for.\nAlways look for original sources references, e.g. don’t ‘cite’ the LLM for use of a GLM, use a textbook or reputable source (Zuur’s books are good for this!)",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Ethics and copyright</span>"
    ]
  },
  {
    "objectID": "09-ethics-copyright.html#managing-data-privacy",
    "href": "09-ethics-copyright.html#managing-data-privacy",
    "title": "9  Ethics and copyright",
    "section": "9.6 Managing data privacy",
    "text": "9.6 Managing data privacy\nAny prompt you send to an LLM provider is going to the server of an AI company (e.g. Google). So its important to be mindful of what information you are including in your prompts.\nThe data you send (including text data) will be covered by the privacy policy of the LLM provider. Some services claim to keep your data private (e.g. the Copilot subscription my University has). Public services will tend to retain the right to use any data you enter as prompts.\nThis means if you put your best research ideas into chatGPT, its possible that it will repeat them later to another user who asks similar questions. So be mindful of what you are writing.\nBefore using an LLM to help with data analysis, be sure you understand the IP and ethical considerations involved with that data. For instance, if you have human survey data you may not be allowed to send that to a foreign server, or reveal any information to an LLM.\nIn that case you have three options.\n\n9.6.0.1 Option 1: Locally hosted LLM\nUse a locally hosted LLM. We won’t cover setting these up in this workshop. Locally hosted LLMs run on your computer. They can be suitable for simpler tasks and if you have a reasonably powerful GPU. Downsides are they do not have the performance of the industry leading LLMs and response times can be slower.\n\n\n9.6.0.2 Option 2: Keep data seperate from code development.\nUse the LLM to help generate code to analyse the data, but do not give the LLM the data or the results. I would recommend keeping the data in a different directory altogether (ie not your project directory), so that LLM agents don’t inadvertently access the raw data. You also want to be sure that the LLM isn’t returning results of data analysis to itself (and therefore you reveal private information to the LLM).\nIt can be helpful to generate some simulated data to use for code development, so there is no risk of violating privacy.\n\n\n9.6.0.3 Option 3: Ignore sensitive folders\nSome LLM agents can be directed to ignore specific folders. e.g. You could add a command to ignore a folder to copilot custom instructions, Roo Code has a .rooignore file for this.\nHowever, remember prompts are not 100% precise (unlike real code), so there’s still the chance the LLM will go in those folders. So be careful, if its really sensitive keep it elsewhere on your computer, and always check its actions before you approve them.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Ethics and copyright</span>"
    ]
  },
  {
    "objectID": "09-ethics-copyright.html#supplement-calculations-of-personal-environmental-impact-from-using-llms",
    "href": "09-ethics-copyright.html#supplement-calculations-of-personal-environmental-impact-from-using-llms",
    "title": "9  Ethics and copyright",
    "section": "9.7 Supplement: Calculations of personal environmental impact from using LLMs",
    "text": "9.7 Supplement: Calculations of personal environmental impact from using LLMs\nA ChatGPT request uses 2.9 watt-hour. So say that’s similar cost for coding applicatoins (probably more due to the additional context we are loading with every prompt). Then looking at my chat history I had 14 conversations in the last week (not counting in-line editing). Average was 3x requests per conversation, so in a year that equals: 2.9 * 14 * 3 * 52 = 6.33 kW-hours In USA energy cost on Average is 367 grams C02 per kW-hour. (https://www.eia.gov/tools/faqs/faq.php?id=74&t=11) So my conservative estimated yearly usage for coding: 6.33 x 367 = 2.32 kg C02 For comparison flying the 1.5 hours from Halifax to Montreal is about 172kg of emissions. So my personal annual emissions for coding are perhaps about 10x than a short plane flight. Water is used for cooling in data centres: “A single ChatGPT conversation uses about fifty centilitres of water, equivalent to one plastic bottle.” Based on calculations above, this equates to about 1000L per year. That’s equivalent to about 22 x 5-minute showers.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Ethics and copyright</span>"
    ]
  },
  {
    "objectID": "10-cost-security.html",
    "href": "10-cost-security.html",
    "title": "10  Cost and security",
    "section": "",
    "text": "10.1 Cost considerations\nAI companies are running at a loss and its quite likely that costs will go up in future. The aim right now is to get us all dependent on the technology, so that we have to keep paying in future (another reason I think its improtant our own countries develop these capaibilites, and that we also need to strive to be capable to work in AI free ways as well. )",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Cost and security</span>"
    ]
  },
  {
    "objectID": "10-cost-security.html#cost-considerations",
    "href": "10-cost-security.html#cost-considerations",
    "title": "10  Cost and security",
    "section": "",
    "text": "PIs need to consider cost and impact on research budget\ne.g. Copilot subscription free for students\nTools like Roo Code can be more expensive (pay per use as using API).\nStill less than a person (currently)\ne.g. processing 6000 abstracts to extract data for a lit review might cost about USD300 (including cost of developing prompts)\nStrategies for optimizing token usage\nBalancing cost with capability requirements",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Cost and security</span>"
    ]
  },
  {
    "objectID": "10-cost-security.html#api-security",
    "href": "10-cost-security.html#api-security",
    "title": "10  Cost and security",
    "section": "10.2 API security",
    "text": "10.2 API security\n\nManaging API keys and credentials\nSanitizing inputs to remove sensitive information\nLocal vs. cloud-based LLM solutions\nAuditing and monitoring LLM interactions",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Cost and security</span>"
    ]
  },
  {
    "objectID": "10-cost-security.html#agent-security",
    "href": "10-cost-security.html#agent-security",
    "title": "10  Cost and security",
    "section": "10.3 Agent security",
    "text": "10.3 Agent security\n\nCan run code on your computer\nBe careful what it is doing\nRead prompts before running them",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Cost and security</span>"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "AI assistants for Scientific Coding",
    "section": "",
    "text": "0.1 Summary\nIf you are doing data analysis you are probably using language models (e.g. ChatGPT) to help you write code, but are you using them in the most effective way? Language models have different biases to humans and so make different types of errors. This book will cover how to use language models to learn scientific computing and conduct reliable environmental analyses. The book is reference material for a 1-day workshop I teach.\nI will cover:\nThe content I’ll teach is suitable for anyone using computing coding (e.g. R, Python) to do data analysis.\nExamples will be in marine conservation science using the R language, but the methods are general to any field. The AI software is also general to any programming language and we won’t be doing much actual coding (the AI does that!) so participants can follow along in other languages if they prefer. To follow the practical applications you will need to have some experience in scientific computing (e.g. R or Python).",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Summary</span>"
    ]
  },
  {
    "objectID": "index.html#summary",
    "href": "index.html#summary",
    "title": "AI assistants for Scientific Coding",
    "section": "",
    "text": "How to use different software tools from the simple interfaces like ChatGPT to advanced tools that can run and test code by themselves and keep going until the analysis is complete (and even written up).\nVibe coding and how future analysis workflows will change dramatically from today\nBest practice prompting techniques that can dramatically improve model performance for complex data analysis\nApplying language models to common environmental applications such as GLMs and multivariate statistics\nIssues including environmental impacts, copyright and ethics\nI’ll also make space for an interactive discussion of people’s concerns about AI, but also the opportunities.\n\n\n\n\n0.1.0.1 Who should read this book?\nThe book is for: anyone who currently uses R, from intermittent users to experienced professionals. The workshop is not suitable for those that need an introduction to R and I’ll assume students know at least what R does and are able to do tasks like read in data and create plots.\nImportant This book isn’t for people who need an introduction to R or Python. I’ll assume students know at least how to do tasks like read in data and create plots in Python or R. To use these AI tools effectively you absolutely have to understand how scientific computing works first. If you need an introduction to R then I recommend you learn it without AI first.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Summary</span>"
    ]
  },
  {
    "objectID": "index.html#about-chris",
    "href": "index.html#about-chris",
    "title": "AI assistants for Scientific Coding",
    "section": "0.2 About Chris",
    "text": "0.2 About Chris\nI’m an Associate Professor of Fisheries Science at University of Tasmania and an Australian Research Council Future Fellow. I specialise in data analysis and modelling, skills I use to better inform environmental decision makers. R takes me many places and I’ve worked with marine ecosystems from tuna fisheries to mangrove forests. I’m an experienced teacher of R. I have taught R to 100s people over the years, from the basics to sophisticated modelling and for everyone from undergraduates to my own supervisors.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Summary</span>"
    ]
  },
  {
    "objectID": "index.html#citation-for-book",
    "href": "index.html#citation-for-book",
    "title": "AI assistants for Scientific Coding",
    "section": "0.3 Citation for book",
    "text": "0.3 Citation for book\nIf following the prompting advice please consider citing my accompanying article, currently in pre-print form:\nCitation: Brown & Spillias (2025). Prompting large language models for quality ecological statistics. Pre-print. https://doi.org/10.32942/X2CS80",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Summary</span>"
    ]
  },
  {
    "objectID": "index.html#software-youll-need-for-this-workshop",
    "href": "index.html#software-youll-need-for-this-workshop",
    "title": "AI assistants for Scientific Coding",
    "section": "0.4 Software you’ll need for this workshop",
    "text": "0.4 Software you’ll need for this workshop\nSave some time for setting up the software, there is a bit to it. You may also need IT help if your computer is locked down. See the Chapter 3 for more detailed instructions.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Summary</span>"
    ]
  },
  {
    "objectID": "index.html#book-overview",
    "href": "index.html#book-overview",
    "title": "AI assistants for Scientific Coding",
    "section": "0.5 Book overview",
    "text": "0.5 Book overview\nNote the book isn’t currently complete. I’ve just posted this so workshop attendees can use the set-up instructions in Chapter 3. Here’s an earlier version of the book that is finished.\nPart 1 Generative AI for research applications\nChapters 4-5 deal with the basics of prompting LLMs, as well as some more advanced research applications such as systematic literature reviewers and automating topic research.\nPart 2 Generative AI coding assistants for scientific computation\nIn chapters 6-8 we’ll look at how you can use coding assistants to improve your scientific coding. These chapters will make use of Github Copilot, those other AI coding assistants can also be used.\nPart 3\nWe’ll discuss ethics, copyright, costs and security in chapters 9-10.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Summary</span>"
    ]
  },
  {
    "objectID": "index.html#data",
    "href": "index.html#data",
    "title": "AI assistants for Scientific Coding",
    "section": "0.6 Data",
    "text": "0.6 Data\nWe’ll load all data files directly via URL in the workshop notes. So no need to download any data now. Details on data attribution are below.\n\n0.6.1 Benthic cover surveys and fish habitat\nIn this course we’ll be analyzing benthic cover and fish survey data. These data were collected by divers doing standardized surveys on the reefs of Kia, Solomon Islands. These data were first publshed by Hamilton et al. 2017 who showed that logging of forests is causing sedimentation and impact habitats of an important fishery species.\nIn a follow-up study Brown and Hamilton 2018 developed a Bayesian model that estimates the size of the footprint of pollution from logging on reefs.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Summary</span>"
    ]
  },
  {
    "objectID": "06-github-copilot.html#inline-code-editing",
    "href": "06-github-copilot.html#inline-code-editing",
    "title": "6  Github copilot for R",
    "section": "",
    "text": "6.1.1 1. Code completion\nThis is only option supported in Rstudio (last time I checked).\nAssuming you have github copilot set-up you just need to start a new R script (remember to keep it organized and give it a useful name) and start typing. You’ll see suggested code completions appear in grey. Hit tab to complete them.\nLet’s read in the benthic site data and fish counts:\n\nlibrary(tidyverse)\nlibrary(readr)\n\ndat &lt;- read_csv(url(\"https://raw.githubusercontent.com/cbrown5/R-llm-workshop/refs/heads/main/resources/fish-coral-cover-sites.csv\"))\n\nhead(dat)\nsummary(dat)\n\nNow try create a ggplot of secchi (a measure of water clarity, higher values mean clearer water) and pres.topa (count of topa, the bumphead parrotfish). Start typing gg and see what happens.\nYou should a recommendation for a ggplot. But it won’t know the variable names.\n\nTip: Sometimes GC gets stuck in a loop and keeps recommending the same line. To break it out of the loop try typing something new.\n\n\n\n6.1.2 2. Using comments\nThe code completion is using your script and all open scripts in VScode to predict your next line of code. It won’t know the variable names unless you’ve provided that. One way is to include them in the readme.md file and have that open, another is to use comments in the active script (which tends to work more reliably), e.g.\n# Make a point plot of secchi against pres.topa\ngg...\nShould get you the write ggplot. Using variable names in your prompts is more precise and will help the LLM guess the right names.\nYou could also try putting key variable names in comments at the top of your script.\nAnother way to use autocomplete is not to write R at all, just to write comments and fix the R code. Try templating a series of plots like:\n# Make a point plot of secchi against pres.topa with a stat_smooth\n\n# Plot logged (two categories) and pres.topa as a boxplot\n\n# Plot CB_cover (branching coral cover) against secchi\nNow go back through and click under each line to get the suggestions.\nThis strategy is great in data wrangling workflows. As a simple example try make this grouped summary using comments only:\n\ndat %&gt;%\n    group_by(logged) %&gt;%\n    summarize(mean_topa = mean(pres.topa), \n                mean_CB = mean(CB_cover))\n\nTo make this I might write this series of comments:\n    #group dat by logged \n    #summarize pres.topa and CB_cover\nIf the variable names are documented above you can ofter be lazier and less precise with variable names here.\n\n\n6.1.3 3. Code completion settings\nClick the octocat in the bottom right corner of VScode to fine-tune the settings. You can enable/disable code completions (sometimes they are annoying e.g. when writing a workshop!).\nYou can also enable ‘next edit suggestions’. These are useful if editing an exisiting file. e.g. if you misspelt ‘sechi’ then updated it in one place, it will suggest updates through the script. Hit tab to move through these.\nThe box will also tell you if indexing is available. Indexing allows AI to search your code faster.\n\n\n6.1.4 4. Inline code generation\nIn VScode you can also access an inline chat box with cmd/cntrl-i. This chat can chat as well as edit code.\nYou can click anywhere and active this. I find it most useful though to select a section of code and then hit cmd/cntrl-i.\nThis is most useful to - Add new code - Explain code - Fix bugs - Add tests\nTry select some of your code (e.g. a ggplot) and ask it to explain what the code does.\nNow try select one of your plots and ask for some style changes (e.g. theme, colours, axes label sizes etc…).\nNow add a bug into one of your plots. See if the inline chatbox can fix the bug.\n\n6.1.4.1 Prompt shortcuts\nUse the / to bring up a list of prompt shortcuts. The most useful in R are /explain, /fix, /tests. Try select some code then use these to see what happens.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Github copilot for R</span>"
    ]
  },
  {
    "objectID": "06-github-copilot.html#planning-your-analysis-with-ask-mode",
    "href": "06-github-copilot.html#planning-your-analysis-with-ask-mode",
    "title": "6  Github copilot for R",
    "section": "6.2 Planning your analysis with Ask mode",
    "text": "6.2 Planning your analysis with Ask mode\n\n6.2.1 Stages of analysis\nThere are overall decisions you need to make when developing your analysis:\n\nWhat types of statistics to use.\nHow to implement those statistics in R code.\n\nIts worthwhile separting these two decisions, as they are different issues. One is a science question, the other is a programming question.\nWhen using Assistants its also worthwhile using different chat sessions to try and find answers.\n\n\n6.2.2 Ask mode\nAsk mode helps you plan analysis and implementation, using context from your project.\nIn VScode click the ‘octocat’ symbol that should be at the top towards the right. This will open the chat window.\nThe chat panel will appear down the bottom of this new sidebar. Confirm that the chatbot is currently set to ‘Ask’ mode.\nYour current file will automatically be included as context for the prompt. You can drag and drop any other files here as well.\nStart by asking the chatbot for guidance on a statistical analysis. We are interested in how the abundance of Topa relates to coral cover. For instance you could ask:\nHow can I test the relationship between pres.topa and CB_cover?\nEvaluate the quality of its response and we will discuss.\n\n\n6.2.3 The jagged frontier of LLM progress\nLLMs were created to write text. But it soon became apparent that they excel at writing programming code in many different languages.\nSince then AI companies have been optimising their training and development for coding and logic.\nThere are a series of standardized tests that are used to compare quality of LLMs. Common evaluation tests are the SWE benchmark which looks at the ability of LLMs to autonomously create bug fixes. Current models get about 50% resolution on this benchmark.\nTheir progress on math and logic is a bit more controversial. It seems like some of the math benchmarks (like AIME annual tests for top 5% highschool students) are saturated as LLMs are scoring close to 100% on these tests.. So newer tests of unsolved maths problems are being developed.\nHowever, others are finding that the ability of LLMs on math and logic are overstated, perhaps because the LLMs have been trained on the questions and the answers. Its also clear that AI companies have a strong financial incentive to find ways (real and otherwise) of improving on the benchmarks. Are the moment there is tough competition to be ‘industry leaders’ and grab market share with impressive results on benchmarks.\nEither way, it does seem that the current areas of progress are programming, math and logic.\nEvaluations on statistics and the R software are less common.\nThe limited evaluations of LLMs on their ability to identify the correct statistical procedure are less impressive than other benchmarks. An evaluation (published 2025) of several models, including GPT-4 as the most up-to-date model, found accuracy at suggesting the correct statistical test of between 8% and 90%.\nIn general LLMs were good at choosing descriptive statistics (accuracy of up to 90% for GPT-4). Whereas when choosing inferential tests accuracy was much less impressive - GPT-4 scored between 20% and 43% accuracy on questions for which a contingency table was the correct answer.\nThe results also indicate the improvements that can be gained through better prompts (i.e. doubling in accuracy for GPT 4).\nThe lesson is two-fold. Just because LLMs excel at some tasks doesn’t mean they will excel at others. Second, good prompting strategies pay off.\nFor us in the niche R world there is also another lesson. The LLMs should be good at helping us implement analyses (ie write the R code). However, they are less reliable as statisticians who can guide us on the scientific question of what type of analysis to do.\n\n\n6.2.4 How to prompt for better statistical advice\nThe limited number of evaluations of LLMs for statistics have found the biggest improvements for prompts that:\n\nInclude domain knowledge in the prompt\nInclude data or summary data in the prompt\nCombine domain knowledge with CoT (but CoT on its own doesn’t help)\n\nIn addition, larger and more up-to-date models tend to be better. e.g. try Claude 4.0 over GPT-mini.\n\n6.2.4.1 What LLMs don’t do that real statisticians do…\nIf you consult a human statistician they’ll usually ask you lots of questions. LLMs, in contrast, will tend to just give you an answer, whether or not they have enough context.\nSay you asked me the same question you had in your LLM prompt like “how do see if fish are related to coral”. There’s no way I’d jump in with an answer with so little information. But the LLM will.\nSo be aware of this shortcoming and come to prompting pre-prepared with the context it will need to give you a better answer.\n\n\n\n\n\n\n\n\n\nFigure 1 Comparison of how an experienced human statistical consultant would structure a conversation compared to a typical prompt chain with an AI assistant (figure 1). The human consultant will usually ask more questions than provide answers at the start of a conversation, then switch to providing more answers once they understand the context of the study. An AI assistant will tend to be constant in the number of questions it asks, unless explictly prompted to ask questions rather than provide answers. This means it provides answers without first gathering appropriate context.\n\n\n6.2.4.2 Guidelines for prompting for statistical advice\nAttach domain knowledge Try to find quality written advice from recognized researchers to include in your prompts.\nAlways provide context on the data For instance, the model will give better advice for the prompt above if we tell it that pres.topa is integer counts (it will probably then recommend poisson GLM straight away). Likewise, if your replicates are different sites, tell that to the model so it has the opportunity to recommend approaches that are appropriate for spatial analysis.\nAttach data to your prompts You can attach the whole dataset if its in plain text (e.g. csv). Or write a summary() and/or head() to file and attach that.\nCombine the above approaches with Chain of Thought Just add ‘use Chain of Thought reasoning’ to your prompt. Its that easy.\nDouble-up on chain of thought with self evaluation After the initial suggest try prompts like “are you sure?”, “Take a deep breath, count to ten and think deeply”, “Evaluate the quality of the options on a 1-5 scale”.\n\nTip: Make a library of reference material for your prompting. If you see vignettes, blogs, or supplemental sections of papers that explain an analysis well, save them as text files to use in prompts.\n\n\n\n6.2.4.3 Improving our initial prompt by attaching data\nRecall our initial prompt was:\nHow can I statistically test the relationship between pres.topa and CB_cover?\nTry some of the strategies above (make a new prompt by clicking the + button) and compare the quality of advice.\nFor instance, you can save a data summary like this:\n\nwrite_csv(head(dat), \"resources/head-site-level-data.csv\")\n\nThen drag and drop it into the ask window and add something like:\nHow can I statistically test the relationship between pres.topa and CB_cover? Here are the first 6 rows of data\n\n\n6.2.4.4 Improving our initial prompt by attaching domain knowledge\nYou can further improve the response by attaching a trusted resource. e.g. save this webpage on count models for ecology to your computer. Then you can attach the html file. That turned out to be a bit slow to compute (file too large?). Would be better if we had in plain text (e.g. copy and paste the text to a file, or use an extraction tool to extract text from the html).\nIf you installed the websearch tool (which will likely become default in future) then you could add a prompt like this:\nHow can I statistically test the relationship between pres.topa and CB_cover? Here are the first 6 rows of data. pres.topa is my response and it is count data. Use @websearch to find robust recommendations for ecologists to analyse count data before proceeding with your recomemndations. \nThat worked well for me. I then followed up with:\nGreat. Evaluate the robustness of each suggestoin on a 1-10 scale\nAnd it gave me a nice summary suggesting to try overdispersion models first (which is a good suggestion).\nThe absolute best practice would be to give the assistant all the context for your study and observational design. Let’s see how doing that can work in our favour when planning implementation.\n\n\n\n6.2.5 Planning implementation\nThe other main way to use Ask mode is for help in implementing an analysis. Many of our workflows are complex and involve multiple data wrangling steps.\nTo get the best out of GC I recommend creating a detailed README.md file with project context. Let’s try that and use it to plan our project.\nSave the README.md that his here to a local file. (Remember that we are going to be using this as a prompt, so read it first).\nNow you can attach it (or open it then click new chat). Given all the context you’ve provided you can just write something simple like:\nHelp me plan R code to implement this analysis. \nOr\nHelp me plan the workflow and scripts to implement this analysis\nI did this. It suggested both code (that looked approximatley correct) and the directory structure, sticking to my guideline in the readme about being modular.\nYou should iterative with Ask mode to if there are any refinements you want.\nLet’s move onto edit mode to see how to put this plan to action.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Github copilot for R</span>"
    ]
  },
  {
    "objectID": "06-github-copilot.html#creating-your-code-with-edit-mode",
    "href": "06-github-copilot.html#creating-your-code-with-edit-mode",
    "title": "6  Github copilot for R",
    "section": "6.3 Creating your code with Edit mode",
    "text": "6.3 Creating your code with Edit mode\nEdit mode will edit files for you. The best way to learn how is to just see it in action.\nOpen the Chat panel and click the ‘Ask’ button, then select ‘Edit’.\n\n6.3.1 Adding a plan to the readme\nOpen the README.md. Then type this prompt:\nHelp me plan the implementation of this project. Add the plan to the ## Steps section\nClick ‘Keep’ if you like what it did. Or you can suggest improvements. Alternatively, accept it for now and then edit it afterwards.\n\nTip: Sometimes you can’t go back once copilot has made edits to a file. So its good practice to use git and commmit changes before and after editing.\n\n\n6.3.1.1 Working through your plan\nOnce you’re happy with the plan, you can get copilot to implement it. You can continue the current chat, or start a new chat to do this (depending on the length of the task).\nNow step through, asking copilot to create each file as you.\nAt this point everyone’s answers will diverge, as there is an element of randomness to the LLM’s responses. We will compare as a class to see if everyone gets to a similar analysis and answer.\n\nTip: We are using the readme.md is copilot’s memory. This means the assitant always has the context it needs across different chat sessions (where it would otherwise forget). So its important to keep the readme updated. Its also useful to help you remember if you come back to the project some months or years later.\n\n\n\n6.3.1.2 Why so much code?\nCopilot is designed as a programming assistant. We don’t know its system message, but given the main market for this software is professional programmers, we can guess it has a strong emphasis on programming robust code.\nYou might notice that copilot tend to ‘over-engineer’ your R scripts. For instance, it has a tendancy to make an if statement to check if each new package needs installing, before loading it.\nIf you don’t like this style you can add a statement to the readme asking it to keep implementation simple.\n\n\n\n6.3.2 Workflows and tips for edit mode\nRemember its an assistant, its not doing the project for you. So you need to make sure it stays on track. Left unattended (if you just accept, accept, accept without reading) it can go down rabbit holes. Sometimes it creates superfluous analyses or even incorret statistics.\nSo here’s how I recommend you use it:\n\nUse git for version control so you can go back in to older versions.\nRead the suggested edits before accepting\nKeep the readme.md updated and keep attaching it to your prompts. This will help keep it focused on the tasks that matter\nUse a two-step approach to identifying the statistical tests first, then implementing them as R code second. If you conflate these tasks you risk letting copilot guide the stats and getting it wrong.\nYou can use it to help implement multiple different types of statistical tests for experimenting. If you do this, I just suggest you still use a two-step approach: plan a list of stats options first, then get copilot to implement them so you can compare results.\n\nNEVER edit the file while copilot is working! To edit files it uses string matching to locate the position to insert the edits. If you change the file it may not find the correct place to insert the new code.\n\nTip: LLMs will tend to suggest the most obvious statistical analyses. If you want to innovate creative new types of analyses you need to work a bit harder. One way to do this is to mix up your prompts to try and get cross-disciplinary pollination. For instance, you could ask it: “Suggest methods I could use for this analysis, taking inspiriation from different disciplines such as medicine, psychology and climate research”.\n\n\n6.3.2.1 Suggested workflow for new analyses\nHere’s a workflow I’ve found works well if I’m doing an analysis that is new to means\n\nRead the literature to identify the appropriate analysis for the research question and data.\nOnce I’ve narrowed down the options I look for useful domain knowledge: vignettes, manuals or blogs that have suitable R examples.\nStart a new folder, setting up the directory and readme as descriped in this workshop.\nUse copilot to implement the analysis, attaching data summaries and the domain knowledge to get the best prompts.\n\n\n\n6.3.2.2 Suggested workflow for analyses I know well\nMuch the same as above, just less planning and you don’t need to search the literature because you know what you want to do. If you save useful domain knowledge when you see it you will also have the documents on hand to support the assistant.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Github copilot for R</span>"
    ]
  },
  {
    "objectID": "06-github-copilot.html#automated-workflows-with-agent-mode",
    "href": "06-github-copilot.html#automated-workflows-with-agent-mode",
    "title": "6  Github copilot for R",
    "section": "6.4 Automated workflows with Agent mode",
    "text": "6.4 Automated workflows with Agent mode\nAgents are LLMs that have tools that allow them to work autonomously. In effect they review the results of tool use (such as writing code and running code), then respond to those results.\nIn Copilot’s chat window you can set it to ‘Agent’ mode to enable these features.\nAfter each tool use copilot will ask you to confirm the changes and the next action. At that point you can review its changes, make edits, or continue chatting to suggest refinements.\n\nAgent mode has access to the terminal, so it will be using the terminal application to run scripts it creates. We’ll demonstrate in class so you can understand what its doing.\nImage: Agent mode from https://code.visualstudio.com\nYou can also just accept every suggestion without reading it, also called ‘vibe coding’. However, I don’t recommend doing that, especially when you are starting out. You need to get a feel of how much direction it needs and problems it might create. Without human intervention the algorithms have a tendency to go off task:\n\n\n\nAttaching package: 'gridExtra'\n\n\nThe following object is masked from 'package:dplyr':\n\n    combine\n\n\n\n\n\n\n\n\n\nHave a readme with clear steps that you attach as a prompt is also helpful for Agent mode. It helps it stay on topic.\nAgent mode also allows installation of additional tools, which we’ll explore later.\n\n6.4.1 Exploring agent mode\nLet’s explore Agent mode’s features through some analysis.\n\n6.4.1.1 Motivating example Bayesian time-series analysis\nWe’ll develop time-series models to forecast rock lobster (Jasus edwardsii) abundance from annual diver surveys. I’ve provided you with summary data. If you want to use this data in your research it is freely available and the original should be downloaded from the AODN portal.\nWe’ll use the INLA package for our time-series models. We’ll fit it for the first part of the data, then we’ll forecast to the last part. In this way we can test the model’s predictions against data that is independent of model fitting (validation).\nThe example is based on my study where I asked how accurately we can forecast species abundance change in dynamic environment. In a rapidly changing environment the models we fit to historical data may no longer make accurate predictions to future, novel, environments. So our current models may overstate the future predictability of ecosystems.\nIn short, the environments we want to predict to in the future have no analogue in contemporary data. This may make accurate prediction more challenging.\nTo explore this idea I developed a new way of validating time-series. I deliberately designed validations that forced the model fitting to be to older data and the forecasting and accuracy evaluation to be on contemporary data. As such, if the environment has changed the parameters the model has learned from the historical data will no longer be relevant in the contemporary environment.\nWe found the new method gave much more pessimistic estimates of model accuracy for species that undergo rapid changes. Whereas for species that have resisted environmental change the new method gave comparable results to traditional methods of validation.\nIn today’s workshop we’ll look at the first step, which is how to fit a model and make forecasts.\nWe chose Bayesian models with INLA because have several advantages over alternatives:\n\nAllow for complex heirarchical models in a familiar GLMM framework - we have structuring by time and sites to consider\nAre computationally fast to run - convenient if you are re-running the model to do cross validation.\nAutomatically handles gaps in time-series - Our data has a gap in 2003 when funding for monitoring wasn’t available\nStraightforward to model non-normal data - we are using counts.\n\nWe’ll use INLA to fit auto-regressive order 1 (AR1) models to rock lobster abundance, with a negative binomial distribution. We’ll also use INLA to make forecasts.\nAnother nice thing about INLA for us is that it has an unusual way of implementing predictions. This tends to trip-up copilot, so we’ll see how to overcome that challenge and get copilot to write correct code.\n\n\n6.4.1.2 Set-up your project\nSet-up a new project, including creating a readme following the structure we used before.\nHere’s the link to the data:\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ forcats   1.0.0     ✔ readr     2.1.5\n✔ lubridate 1.9.3     ✔ stringr   1.5.1\n✔ purrr     1.0.2     ✔ tibble    3.2.1\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ gridExtra::combine() masks dplyr::combine()\n✖ dplyr::filter()      masks stats::filter()\n✖ dplyr::lag()         masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\ndat &lt;- readr::read_csv(url(\"https://raw.githubusercontent.com/cbrown5/R-llm-workshop/refs/heads/main/resources/ATRC-RLS-jasus-edwardsii-maria-island.csv\"))\n\nRows: 1844 Columns: 9\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): species_name, site_code, protection_status, site\ndbl (5): survey_id, total, latitude, longitude, year\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nYou can see the readme.md I used to get started here. I encourage you to write your own to get a feel for how it works and develop your own style.\n\n\n6.4.1.3 Prompts I used\nOnce I had the folder and readme set-up here’s the series of prompts I used. I encourage you to explore making your own. I used Claude 4.0 as the model option. I’ve found that GPT occaisonally makes errors with tool use or stuffs up text matching when editing files (meaning it inserts text in the wrong place).\nI started a new chat session between each of these prompts. This helps manage the context window. I’m relying on updating the readme.md so Copilot has memory (and I get it to update that).\nStart by documenting the directory structure in the readme.md\nI'd be most pleased if you can undertake to perform steps 1-2. Document the data variables in the readme when you are done. \n\nTip: There’s no ‘optimal’ prompt, only better prompts. Sometimes the best way to write is the way you are most comfortable writing. You’ll get more out of your brain that way and copilot will end up performing the same.\n\nAhoy you salty sea dog, we've scrubbed down steps 1 and 2, time for you to raise the sail on step 3!\n(Ok so that last prompt definitely doesn’t follow the guidelines of being super clear, but I was bored and it seemed to work ok)\nIt wrote some nice code for step 3, but had some problems with model convergence. At this point I intervened manually and edited the model myself. I didn’t really want it deciding the model structure for me, as I knew what I wanted (below is the model I used FYI). That fixed it and I got it to document the changes then started a new chat.\nNote that the Agent changed the default fitting algorithm, which I wasn’t pleased with. So always important to check the details.\nsimple_model_formula &lt;- total_lobsters ~ 1 + \n  protection_status +\n  f(site_numeric, model = \"iid\") +\n  f(year, model = \"ar1\", hyper = ar1_prior)\n\nar1_model &lt;- inla(\n  formula = simple_model_formula,\n  data = train_data,\n  family = \"nbinomial\",  # Use negative binomial for count data\n  control.predictor = list(compute = TRUE),\n  control.compute = list(\n    dic = TRUE, \n    waic = TRUE,\n    cpo = FALSE,  # Disable CPO to help convergence\n    config = FALSE\n  ),\n  verbose = FALSE\n)\nAfter fixing the model and updated the readme, here’s the next step:\nAlright cobber, take you best shot at step 4\nThat worked, which actually I was expecting it not to work based on prior experience. INLA does predictions as part of model fitting, so you can’t predict(model1) like you can with other packages.. I’ve found that often trips up copilot when it tries to predict directly from the model object. It might be that Claude 4.0 (only came out as I was writing this) now ‘knows’ not to make that mistake.\nI tried again with Claude 3.5 (older version) to see if I could fool that one. However, it avoided the problem by writing a custom fitting function (which would need careful checking).\nAnyway, the lesson was meant to be to show you how to solve these types of problems by attaching domain knowledge like the FAQ linked above.\nCopilot agent did have some problems running Rscript on my computer (used to source R files from terminal). So I added this line to the readme to help it: When using Rscript from terminal be sure to put the script in ““, e.g. Rscript \"Scripts/script1.R\"\nJust step 5 left to go, make me some nice plots using the types of colours that Wes Anderson would choose\n\n\n6.4.1.4 Writing up the project?\nYou can keep going from here if you like and get agent mode to write up the results it found as an Rmd file. It will use the tables it generates to (hopefully) make accurate interpretations. Pretty soon Copilot will also have vision capabilities (currently available in preview mode as of 2025-05-27). This means it will be able to interpret the figures it creates as well. We’ll see that in action when we look at Roo Code in a bit.\nIf you do that, as always, don’t take anything for granted. Make sure you check everything and understand the results yourself.\n\n\n6.4.1.5 Custom intstructions\nFor heavy agent use you may want to set-up custom instructions. These apply to all prompts in a project. e.g. you could set preference for ggplot2, or tell it how to use Rscript to avoid terminal errors See here for instructions.\n\n\n\n6.4.2 Summary\nAgent mode can really accelerate your workflow development. But there are some risks. It can also go off track or write excessive amounts of code (over-engineering). Best practices for using Agent mode include:\n\nSeparate science questions (what stats) from implementation stats (what code)\nUnderstand the stats you want to do, don’t just rely on copilot to get it right\nChecking what it does at is does it, so you can keep it on track\nGiving strong guidelines e.g. through a project readme file.\nKeeping the readme updated to guide copilot\nReport AI use and how it was used in your publications",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Github copilot for R</span>"
    ]
  },
  {
    "objectID": "07-ai-powered-analysis-workflows.html",
    "href": "07-ai-powered-analysis-workflows.html",
    "title": "7  AI powered analysis workflows",
    "section": "",
    "text": "This section about advice for workflows",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>AI powered analysis workflows</span>"
    ]
  },
  {
    "objectID": "08-specification-sheets.html",
    "href": "08-specification-sheets.html",
    "title": "8  Best practices project setup",
    "section": "",
    "text": "8.1 Project organization\nIts helpful to set-up your projects in an organized and modularised way. In my experience most R users write most of their analysis in one long script. Don’t do this. It will be hard for ‘future you’ to navigate. If its hard for a human to navigate, it will also be hard for the assistant. Here’s how I set-up my projects.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Best practices project setup</span>"
    ]
  },
  {
    "objectID": "08-specification-sheets.html#project-organization",
    "href": "08-specification-sheets.html#project-organization",
    "title": "8  Best practices project setup",
    "section": "",
    "text": "8.1.1 General guidance\n\nCreate a new folder for each new project.\nOptional but recommended: Initiliaze a git repo in that folder (I use github desktop).\nSet-up folders and files in an organized way\nIdeally put the data in this folder also. However, large datasets or sensitive data can be kept in other folders.\nKeep scripts short and modularized (e.g one for data analysis, one for modelling).\n\nOnce you have your folder you can make it an Rstudio project (if using Rstudio) or just use ‘open folder’ in vscode. If want to link multiple folders in then use VScode workspaces.\nIf you are not using git (version control), then I recommend you learn. LLM code editing tools can cause you to lose older versions. So best to back them up with proper use of git.\n\n\n8.1.2 Project directory structure example\nHere’s an example of a project directory structure. You don’t have to use this strucutre. the important thing is to be organized.\nmy-project/\n├── README.md \n├── .gitignore\n├── Scripts/ # R code\n│   ├── 01_data-prep.R\n│   ├── 02_data-analysis.R\n│   └── 03_plots.R\n├── Shared/       \n│   ├── Outputs/\n│   │   ├── Figures/\n│   │   ├── data-prep/\n│   │   └── model-objects/\n│   ├── Data/\n│   └── Manuscripts/   \n└── Private/",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Best practices project setup</span>"
    ]
  },
  {
    "objectID": "08-specification-sheets.html#the-readme.md-file",
    "href": "08-specification-sheets.html#the-readme.md-file",
    "title": "8  Best practices project setup",
    "section": "8.2 The README.md file",
    "text": "8.2 The README.md file\nThe README.md is the memory for the project. If you use github it will also be the landing page for your repo, which is handy.\nRemember you are writing this for you and the LLMs. So think of it like a prompt.\nHere’s an example of some of the information you might want to include in your readme.\n# PROJECT TITLE\n\n## Summary\n\n## Aims\n\n## Data methodology\n\n## Analysis methodology\n\n## Tech context\n- We will use the R program\n- tidyverse packages for data manipulation\n- ggplot2 for data visualization\n\nKeep your scripts short and modular to facilitate debugging. Don't complete all of the steps below in one script. Finish scripts where it makes sense and save intermediate datasets. \n\n## Steps\nAs you go tick of the steps below. \n\n[ ] Wrangle data\n[ ] Fit regression\n[ ] Plot verification\n[ ] ... \n\n## Data \n\nInclude meta-data here and file paths. \n\n## Directory structure \n\nmy-project/\n├── README.md \n├── .gitignore\n├── Scripts/ # R code\n│   ├── 01_data-prep.R\n│   ├── 02_data-analysis.R\n│   └── 03_plots.R\n├── Shared/       \n│   ├── Outputs/\n│   │   ├── Figures/\n│   │   ├── data-prep/\n│   │   └── model-objects/\n│   ├── Data/\n│   └── Manuscripts/   \n└── Private/",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Best practices project setup</span>"
    ]
  },
  {
    "objectID": "08-specification-sheets.html#example-data",
    "href": "08-specification-sheets.html#example-data",
    "title": "8  Best practices project setup",
    "section": "8.3 Example data",
    "text": "8.3 Example data\nFor the next few chapters we’ll work with some ecological data on benthic marine habitats and fish.\n\n8.3.1 Case-study: Bumphead parrotfish, ‘Topa’ in Solomon Islands\nBumphead parrotfish (Bolbometopon muricatum) are an enignmatic tropical fish species. Adults of these species are characterized by a large bump on their forehead that males use to display and fight during breeding. Sex determination for this species is unknown, but it is likely that an individual has the potential to develop into either a male or female at maturity.\nAdults travel in schools and consume algae by biting off chunks of coral and in the process they literally poo out clean sand. Because of their large size, schooling habit and late age at maturity they are susceptible to overfishing, and many populations are in decline.\nTheir lifecycle is characterized by migration from lagoonal reef as juveniles (see image below) to reef flat and exposed reef habitats as adults. Early stage juveniles are carnivorous and feed on zooplankton, and then transform into herbivores at a young age.\n\nImage: Lifecycle of bumphead parrotfish. Image by E. Stump and sourced from Hamilton et al. 2017.\nUntil the mid 2010s the habitat for settling postlarvae and juveniles was a mystery. However, the pattern of migrating from inshore to offshore over their known lifecycle suggests that the earliest benthic lifestages (‘recruits’) stages may occur on nearshore reef habitats.\nNearshore reef habitats are susceptible to degradation from poor water quality, raising concerns that this species may also be in decline because of pollution. But the gap in data from the earliest lifestages hinders further exploration of this issue.\nIn this course we’ll be analyzing the first survey that revealed the habitat preferences of early juveniles stages of bumphead parrotfish. These data were analyzed by Hamilton et al. 2017 and Brown and Hamilton 2018.\nIn the 2010s Rick Hamilton (The Nature Conservancy) lead a series of surveys in the nearshore reef habitats of Kia province, Solomon Islands. The aim was to look for the recruitment habitat for juvenile bumphead parrotfish. These surveys were motivated by concern from local communities in Kia that topa (the local name for bumpheads) are in decline.\nIn the surveys, divers swam standardized transects and searched for juvenile bumphead in nearshore habitats, often along the edge of mangroves. All together they surveyed 49 sites across Kia.\nThese surveys were made all the more challenging by the occurrence of crocodiles in mangrove habitat in the region. So these data are incredibly valuable.\nLogging in the Kia region has caused water quality issues that may impact nearshore coral habitats. During logging, logs are transported from the land onto barges at ‘log ponds’. A log pond is an area of mangroves that is bulldozed to enable transfer of logs to barges. As you can imagine, logponds are very muddy. This damage creates significant sediment runoff which can smother and kill coral habitats.\nRick and the team surveyed reefs near logponds and in areas that had no logging. They only ever found bumphead recruits hiding in branching coral species.\nIn this course we will first ask if the occurrence of bumphead recruits is related to the cover of branching coral species. We will then develop a statistical model to analyse the relationship between pollution from logponds and bumphead recruits, and use this model to predict pollution impacts to bumpheads across the Kia region.\nThe data and code for the original analyses are available at my github site. In this course we will use simplified versions of the original data. We’re grateful to Rick Hamilton for providing the data for this course.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Best practices project setup</span>"
    ]
  },
  {
    "objectID": "09-advanced-llm-agents.html",
    "href": "09-advanced-llm-agents.html",
    "title": "9  Advanced LLM agents",
    "section": "",
    "text": "Time: 3:00-3:30pm\nSoftware requirements: VScode with R, Roo code, API license.\nWe’ll take a quick look at Roo Code and its customization options.\nRoo code is more complex and expensive to use than copilot, but allows significant amounts of customization to make bespoke agents that can help with the scientific process.\nI’ll use an example with the Benthic Data analysis (benthic-readme.md).\nTalk through:\n\nAPI access\nModel options\nCustomizing system message\nContext window management\nCost\nVision capabilities",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Advanced LLM agents</span>"
    ]
  },
  {
    "objectID": "10-ethics-copyright.html",
    "href": "10-ethics-copyright.html",
    "title": "10  Ethics and copyright",
    "section": "",
    "text": "10.1 Impacts on learning\nDoes AI make our brains lazy? One study found less engagement and deep thinking for students who had access to chatGPT for writing an essay compared to students who just had web searches or had no internet connectivity.\nI think the upshot is using it deliberatley and being careful not to replace your own creativity.",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Ethics and copyright</span>"
    ]
  },
  {
    "objectID": "10-ethics-copyright.html#sustainability",
    "href": "10-ethics-copyright.html#sustainability",
    "title": "10  Ethics and copyright",
    "section": "10.2 Sustainability",
    "text": "10.2 Sustainability\nTraining LLMs costs millions of dollars, much of this cost is energy use. Further, the data centres for training and running LLMs need water for cooling. Asking a finished LLM questions uses much less energy, but cumulatively across the globe it adds up to a lot. Here are a few informative statistics I found online:\nFrom Forbes:\n\n“ChatGPT’s daily power usage is nearly equal to 180,000 U.S. households, each using about twenty-nine kilowatts.”\nMicrosoft emissions have risen 30% since 2020 due to data centers\nAI prompts use 10x more energy than a traditional google search\n\nTo put it in context I did some calculations on my personal usage. I estimate the prompting I do through copilot each year will cost about 2.32 kg of C02 and about 1000 litres of water. (this is lower bound, as I also using LLMs for other tasks).\nTo put that in context, flying the 1.5 hours from Halifax to Montreal is about 172kg of emissions, driving 15 minutes is about 3 kg. So I’m using approximately 10 less than a short flight, or the same as driving to work once. 1000L is equivalent to taking about 22 5-minute showers.\nOf course, the carbon cost is global, whereas the water cost is localised (Probably to US data centres, so by using this resource I’m really just making the water problem worse for Americans. )\nSo its not a huge increase in my personal energy use. But cumulatively across the globe it is a lot.\nMore generally, humanities energy use is growing exponential. Despite renewables and so on, ultimately our planet won’t be able to sustain this energy drawdown. LLMs are part of that trend of growing energy use. At some point we need to start using less energy, or the biosphere will become depleted and return to a ‘moon like rock’ in one study’s words.\nHere’s my personal belief.\nIf we’re smart humanity will use this technology to find ways to make our use of the planet more sustainable and ultimately save water and energy. Just like we should have been using fossil fuels to develop a transition to lasting sustainanle energy use. So you can guess how likely that is to happen…\nIts the reason I’m teaching this course. I don’t personally think that LLMs make our lives better, or humanity more sustainable. They just raise the bar on the rate of progress.\nYou can bet industries are using this technology to improve their productivity (= greater environmental impacts). I believe as environmental scientists we need to try to keep up. Ultimately we need progress on local to planetary sustainability (environmental scientists) to outpace the development of the industries that are environmentally unsustainable.",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Ethics and copyright</span>"
    ]
  },
  {
    "objectID": "10-ethics-copyright.html#model-biases",
    "href": "10-ethics-copyright.html#model-biases",
    "title": "10  Ethics and copyright",
    "section": "10.3 Model biases",
    "text": "10.3 Model biases\nThis is a big one. I recommend everyone read this perspective on the ‘Illusion of Understanding’\nIts important that we don’t become too reliant on AI for our work. That’s why I’m teaching and promoting thoughtful use.\nSome key points:\n\nWe need to maintain and grow research fields that aren’t convenient to do with AI, not just grow the stuff that’s easy with AI\nWe need to push ourselves as individuals to not ‘be lazy’ and rely on AI too much. There is still great value in human learning. This requires mental energy, for instance, you will know something better if you write it yourself rather than write it with AI.\nWe need to be aware of biases in the content AI generates\n\nFor statistics these biases are likely to be a preference for well-known methods developed by Western science. So you should still read the literature broadly and avoid using AI, or prompt it in different ways, if you truly want to create novel statitistics (as opposed to using it to do statistics on a study that is otherwise novel data etc…)",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Ethics and copyright</span>"
    ]
  },
  {
    "objectID": "10-ethics-copyright.html#rising-inequality",
    "href": "10-ethics-copyright.html#rising-inequality",
    "title": "10  Ethics and copyright",
    "section": "10.4 Rising inequality",
    "text": "10.4 Rising inequality\nAI development is currently concentrated in the USA and profits for LLM use go to American companies. (USA is itself a country with massive inequality issues!). So the extent to LLMs replaces labour will redirect income and taxes from jobs in countries to American companies.\nIt is likely that the current low cost of LLM use will not continue. Companies are running at a loss in order to gain market share. So be careful how dependent you become on the LLMs and what that budget is replacing in your research budgets.\nI personally beleive that our own countries should be developing our own LLM products and resources. Even if they are not ‘industry leading’ they can still be highly effective for specific tasks. There are open-source models available that can fill this role.",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Ethics and copyright</span>"
    ]
  },
  {
    "objectID": "10-ethics-copyright.html#copyright",
    "href": "10-ethics-copyright.html#copyright",
    "title": "10  Ethics and copyright",
    "section": "10.5 Copyright",
    "text": "10.5 Copyright\nMany LLMs have been trained on pirated books. The extent to which this is recognized by law is still in court.\nFor me personally its frustrating that I spent years developing a statistics blog (which was open-access, but I appreciated attribution), but now that information has been mined by LLMs. Thus AI companies are profiting from our collective knowledge.\nIt is an even worse situation for authors who’s livelihoods and careers depend on their copyrighted works.\nCopilot does in theory block itself from writing code that might be copyrighted. However, the efficacy of this system is unclear (it seems to just be a command in the system prompt). So be careful. Here are some recommendations for individuals\n\nIn general you own works you create with an LLM.\nThis also means you have the liability for any works you create (not normally an issue in environmental sciences).\ne.g. you couldn’t blame the LLM if you had to retract a paper due to incorrect statistics.\nYou should acknolwedge LLM use in academic publications, and what you used it for.\nAlways look for original sources references, e.g. don’t ‘cite’ the LLM for use of a GLM, use a textbook or reputable source (Zuur’s books are good for this!)",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Ethics and copyright</span>"
    ]
  },
  {
    "objectID": "10-ethics-copyright.html#managing-data-privacy",
    "href": "10-ethics-copyright.html#managing-data-privacy",
    "title": "10  Ethics and copyright",
    "section": "10.6 Managing data privacy",
    "text": "10.6 Managing data privacy\nAny prompt you send to an LLM provider is going to the server of an AI company (e.g. Google). So its important to be mindful of what information you are including in your prompts.\nThe data you send (including text data) will be covered by the privacy policy of the LLM provider. Some services claim to keep your data private (e.g. the Copilot subscription my University has). Public services will tend to retain the right to use any data you enter as prompts.\nThis means if you put your best research ideas into chatGPT, its possible that it will repeat them later to another user who asks similar questions. So be mindful of what you are writing.\nBefore using an LLM to help with data analysis, be sure you understand the IP and ethical considerations involved with that data. For instance, if you have human survey data you may not be allowed to send that to a foreign server, or reveal any information to an LLM.\nIn that case you have three options.\n\n10.6.0.1 Option 1: Locally hosted LLM\nUse a locally hosted LLM. We won’t cover setting these up in this workshop. Locally hosted LLMs run on your computer. They can be suitable for simpler tasks and if you have a reasonably powerful GPU. Downsides are they do not have the performance of the industry leading LLMs and response times can be slower.\n\n\n10.6.0.2 Option 2: Keep data seperate from code development.\nUse the LLM to help generate code to analyse the data, but do not give the LLM the data or the results. I would recommend keeping the data in a different directory altogether (ie not your project directory), so that LLM agents don’t inadvertently access the raw data. You also want to be sure that the LLM isn’t returning results of data analysis to itself (and therefore you reveal private information to the LLM).\nIt can be helpful to generate some simulated data to use for code development, so there is no risk of violating privacy.\n\n\n10.6.0.3 Option 3: Ignore sensitive folders\nSome LLM agents can be directed to ignore specific folders. e.g. You could add a command to ignore a folder to copilot custom instructions, Roo Code has a .rooignore file for this.\nHowever, remember prompts are not 100% precise (unlike real code), so there’s still the chance the LLM will go in those folders. So be careful, if its really sensitive keep it elsewhere on your computer, and always check its actions before you approve them.",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Ethics and copyright</span>"
    ]
  },
  {
    "objectID": "10-ethics-copyright.html#supplement-calculations-of-personal-environmental-impact-from-using-llms",
    "href": "10-ethics-copyright.html#supplement-calculations-of-personal-environmental-impact-from-using-llms",
    "title": "10  Ethics and copyright",
    "section": "10.7 Supplement: Calculations of personal environmental impact from using LLMs",
    "text": "10.7 Supplement: Calculations of personal environmental impact from using LLMs\nA ChatGPT request uses 2.9 watt-hour. So say that’s similar cost for coding applicatoins (probably more due to the additional context we are loading with every prompt). Then looking at my chat history I had 14 conversations in the last week (not counting in-line editing). Average was 3x requests per conversation, so in a year that equals: 2.9 * 14 * 3 * 52 = 6.33 kW-hours In USA energy cost on Average is 367 grams C02 per kW-hour. (https://www.eia.gov/tools/faqs/faq.php?id=74&t=11) So my conservative estimated yearly usage for coding: 6.33 x 367 = 2.32 kg C02 For comparison flying the 1.5 hours from Halifax to Montreal is about 172kg of emissions. So my personal annual emissions for coding are perhaps about 10x than a short plane flight. Water is used for cooling in data centres: “A single ChatGPT conversation uses about fifty centilitres of water, equivalent to one plastic bottle.” Based on calculations above, this equates to about 1000L per year. That’s equivalent to about 22 x 5-minute showers.",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Ethics and copyright</span>"
    ]
  },
  {
    "objectID": "11-cost-security.html",
    "href": "11-cost-security.html",
    "title": "11  Cost and security",
    "section": "",
    "text": "11.1 Cost considerations\nAI companies are running at a loss and its quite likely that costs will go up in future. The aim right now is to get us all dependent on the technology, so that we have to keep paying in future (another reason I think its improtant our own countries develop these capaibilites, and that we also need to strive to be capable to work in AI free ways as well. )",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Cost and security</span>"
    ]
  },
  {
    "objectID": "11-cost-security.html#cost-considerations",
    "href": "11-cost-security.html#cost-considerations",
    "title": "11  Cost and security",
    "section": "",
    "text": "PIs need to consider cost and impact on research budget\ne.g. Copilot subscription free for students\nTools like Roo Code can be more expensive (pay per use as using API).\nStill less than a person (currently)\ne.g. processing 6000 abstracts to extract data for a lit review might cost about USD300 (including cost of developing prompts)\nStrategies for optimizing token usage\nBalancing cost with capability requirements",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Cost and security</span>"
    ]
  },
  {
    "objectID": "11-cost-security.html#api-security",
    "href": "11-cost-security.html#api-security",
    "title": "11  Cost and security",
    "section": "11.2 API security",
    "text": "11.2 API security\n\nManaging API keys and credentials\nSanitizing inputs to remove sensitive information\nLocal vs. cloud-based LLM solutions\nAuditing and monitoring LLM interactions",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Cost and security</span>"
    ]
  },
  {
    "objectID": "11-cost-security.html#agent-security",
    "href": "11-cost-security.html#agent-security",
    "title": "11  Cost and security",
    "section": "11.3 Agent security",
    "text": "11.3 Agent security\n\nCan run code on your computer\nBe careful what it is doing\nRead prompts before running them",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Cost and security</span>"
    ]
  }
]