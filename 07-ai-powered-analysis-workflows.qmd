# AI powered analysis workflows 

Now you are familiar with some of the software options, let's look at how to use these tools in AI powered analysis workflows and some best practice prompting guidelines. 

![](resources/figure2-brown-spillias.png)

## Break your problems into parts 

> Take all your problems and rip 'em apart  
> Carry them off in a shopping cart  
> Another thing you should've known from the start  
> The problems in hand are lighter than at heart...  
> And another thing you have to know in this world  
> Cut up your hair, straighten your curls  
> Well, your problems hide in your curls

*Little Acorns by The White Stripes* 




## General prompting advice 

### Be clear and specific

### Give lots of details 

### Put everything up front, rather than engaging in conversation 

## Stages of analysis

## Select statistical analysis 

### Web search

## Plan implementation and project structure 

## Writing the code

## Iterating 



### Stages of analysis 

There are overall decisions you need to make when developing your analysis:

1. What types of statistics to use. 
2. How to implement those statistics in R code. 

Its worthwhile separting these two decisions, as they are different issues. One is a science question, the other is a programming question. 

When using Assistants its also worthwhile using different chat sessions to try and find answers. 


#### Suggested workflow for new analyses

Here's a workflow I've found works well if I'm doing an analysis that is new to means

1. Read the literature to identify the appropriate analysis for the research question and data. 

2. Once I've narrowed down the options I look for useful domain knowledge: vignettes, manuals or blogs that have suitable R examples. 

3. Start a new folder, setting up the directory and readme as descriped in this workshop. 

4. Use copilot to implement the analysis, attaching data summaries and the domain knowledge to get the best prompts. 

#### Suggested workflow for analyses I know well

Much the same as above, just less planning and you don't need to search the literature because you know what you want to do. If you save useful domain knowledge when you see it you will also have the documents on hand to support the assistant. 

### How to prompt for better statistical advice

The limited number of evaluations of LLMs for statistics have found the biggest improvements for prompts that:

- Include domain knowledge in the prompt
- Include data or summary data in the prompt
- Combine domain knowledge with CoT (but CoT on its own doesn't help)

In addition, larger and more up-to-date models tend to be better. e.g. try Claude 4.0 over GPT-mini.  

::: {.tip}
**Tip:** LLMs will tend to suggest the most obvious statistical analyses. If you want to innovate creative new types of analyses you need to work a bit harder. One way to do this is to mix up your prompts to try and get cross-disciplinary pollination. For instance, you could ask it: "Suggest methods I could use for this analysis, taking inspiriation from different disciplines such as medicine, psychology and climate research".
:::

#### What LLMs don't do that real statisticians do... 

If you consult a human statistician they'll usually ask you lots of questions. LLMs, in contrast, will tend to just give you an answer, whether or not they have enough context. 

Say you asked me the same question you had in your LLM prompt like "how do see if fish are related to coral". There's no way I'd jump in with an answer with so little information. But the LLM will. 

So be aware of this shortcoming and come to prompting pre-prepared with the context it will need to give you a better answer. 


```{r echo=FALSE, message=FALSE,warning=FALSE}
library(ggplot2)
library(tidyr)
library(dplyr)
# Create sample data
time <- seq(1, 10)

# Human consultant data - starts with questions, transitions to more answers with a curved pattern
human_questions <- c(8, 7.5, 6.7, 5.6, 4.4, 3.2, 2.1, 1.4, 1.1, 1)
human_answers <- c(1, 1.8, 2.7, 3.9, 5.2, 6.4, 7.3, 7.8, 8, 8.2)

# AI assistant data - consistently gives more answers than asks questions (with slight wobble)
ai_questions <- c(2.2, 1.8, 2.1, 2.3, 1.9, 2.2, 1.8, 2.1, 1.9, 2.2)
ai_answers <- c(7.1, 7.3, 6.8, 7.2, 6.9, 7.4, 7, 7.2, 6.8, 7.1)

# Combine data
df <- data.frame(
  time = rep(time, 4),
  number = c(human_questions, human_answers, ai_questions, ai_answers),
  type = rep(c(rep("Questions", 10), rep("Answers", 10)), 2),
  source = c(rep("Human consultant", 20), rep("AI assistant", 20))
)

# Create plot
ggplot(df, aes(x = time, y = number, color = type, group = type)) +
  geom_line(size = 1.2) +
  facet_wrap(~ source, ncol = 2) +
  labs(x = "Time in conversation", 
       y = "Number of \n questions and answers",
       color = "") +
  theme_bw(base_size = 14) +
  scale_color_manual(values = c("Questions" = "#E69F00", "Answers" = "#009E73")) +
  theme(
    legend.position = "top",
    strip.text = element_text(size = 14, face = "bold"),
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
    axis.text.x = element_blank(),
    axis.text.y = element_blank(),
    axis.ticks = element_blank(),
    strip.background = element_rect(fill = "white")
  )

```

**Figure 1 From Brown and Spillias in review** Comparison of how an experienced human statistical consultant would structure a conversation compared to a typical prompt chain with an AI assistant (figure 1). The human consultant will usually ask more questions than provide answers at the start of a conversation, then switch to providing more answers once they understand the context of the study. An AI assistant will tend to be constant in the number of questions it asks, unless explictly prompted to ask questions rather than provide answers. This means it provides answers without first gathering appropriate context. 

#### Guidelines for prompting for statistical advice

**Attach domain knowledge** Try to find quality written advice from recognized researchers to include in your prompts. 

**Always provide context on the data** For instance, the model will give better advice for the prompt above if we tell it that `pres.topa` is integer counts (it will probably then recommend poisson GLM straight away). Likewise, if your replicates are different sites, tell that to the model so it has the opportunity to recommend approaches that are appropriate for spatial analysis. 

**Attach data to your prompts** You can attach the whole dataset if its in plain text (e.g. csv). Or write a `summary()` and/or `head()` to file and attach that. 

**Combine the above approaches with Chain of Thought** Just add 'use Chain of Thought reasoning' to your prompt. Its that easy. 

**Double-up on chain of thought with self evaluation** After the initial suggest try prompts like "are you sure?", "Take a deep breath, count to ten and think deeply", "Evaluate the quality of the options on a 1-5 scale". 

::: {.tip}
**Tip:** Make a library of reference material for your prompting. If you see vignettes, blogs, or supplemental sections of papers that explain an analysis well, save them as text files to use in prompts. 
:::

### With web tools

## 



#### Working through your plan 

Once you're happy with the plan, you can get copilot to implement it. You can continue the current chat, or start a new chat to do this (depending on the length of the task). 

Now step through, asking copilot to create each file as you. 

At this point everyone's answers will diverge, as there is an element of randomness to the LLM's responses. We will compare as a class to see if everyone gets to a similar analysis and answer. 

::: {.tip}
**Tip:** We are using the readme.md is copilot's memory. This means the assitant always has the context it needs across different chat sessions (where it would otherwise forget). So its important to keep the readme updated. Its also useful to help you remember if you come back to the project some months or years later. 
:::


- Keep the readme.md updated and keep attaching it to your prompts. This will help keep it focused on the tasks that matter
- Use a two-step approach to identifying the statistical tests first, then implementing them as R code second. If you conflate these tasks you risk letting copilot guide the stats and getting it wrong. 
- You can use it to help implement multiple different types of statistical tests for experimenting. If you do this, I just suggest you still use a two-step approach: plan a list of stats options first, then get copilot to implement them so you can compare results. 


## Agents 



You can also just accept every suggestion without reading it, also called 'vibe coding'. However, I don't recommend doing that, especially when you are starting out. You need to get a feel of how much direction it needs and problems it might create. Without human intervention the algorithms have a tendency to go off task: 

```{r eval = TRUE, echo=FALSE}
library(ggplot2)
library(grid)
library(gridExtra)

# Create data for the workflows, now flowing vertically
workflow1 <- data.frame(
    x = rep(1, 100),
    y = seq(0, 10, length.out = 100)
)

# Add checkin points
checkins <- data.frame(
    x = rep(1, 5),
    y = seq(1, 9, by = 2)
)

# Create divergent workflow
workflow2 <- data.frame(
    x = 1 + 0.2 * (seq(0, 10, length.out = 100) - 3)^2 / 10,
    y = seq(0, 10, length.out = 100)
)
workflow2$x[1:31] <- 1

# Create the plot
p <- ggplot() +
    # Draw workflows
    geom_path(data = workflow1, aes(x = x, y = y), 
                        color = "blue", size = 1, arrow = arrow(length = unit(0.3, "cm"))) +
    geom_path(data = workflow2, aes(x = x, y = y), 
                        color = "red", size = 1,  arrow = arrow(length = unit(0.3, "cm"))) +
    # Add checkin points
    geom_point(data = checkins, aes(x = x, y = y), 
                         color = "blue", size = 3) +
    # Add start and end points (now at top and bottom)
    annotate("text", x = 1, y = -0.3, label = "A (Start)", size = 8) +
    annotate("text", x = 1, y = 11, label = "B (Goal)", size = 8) +
    
    # Add labels
    annotate("text", x = 0.7, y = 5, label = "Workflow with checkins", color = "blue", size = 7, angle = 90) +
    annotate("text", x = 2.5, y = 7, label = "Divergent workflow\n(no checkins)", color = "red", size = 7) +
    
    # Theme adjustments
    theme_minimal() +
    theme(
        axis.title = element_blank(),
        axis.text = element_blank(),
        axis.ticks = element_blank(),
        panel.grid = element_blank()
    ) +
    ylim(-0.5, 11) +
    xlim(0.5, 3.5)

p
```

Have a readme with clear steps that you attach as a prompt is also helpful for Agent mode. It helps it stay on topic. 

Agent mode also allows installation of additional tools, which we'll explore later. 

## AI in the creative scientific process

Ecological modelling is a creative art with rules. The rules are the scientific method, the medium is math, logic and code. 

Iterating, getting ideas.

Add it as a tool inyour belt, not a replacement. Talking to clleagues, reading, sitting on a board looking at the ocean, having showers etc... are all stil important. 