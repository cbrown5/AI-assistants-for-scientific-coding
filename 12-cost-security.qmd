# Cost and security

This chapter addresses important practical considerations when using LLMs for R programming:

## Cost considerations

- PIs need to consider cost and impact on research budget
- e.g. Copilot subscription free for students
- Tools like Roo Code can be more expensive (pay per use as using API). 
- Still less than a person (currently)
- e.g. processing 6000 abstracts to extract data for a lit review might cost about USD300 (including cost of developing prompts)
- Strategies for optimizing token usage
- Balancing cost with capability requirements

AI companies are running at a loss and its quite likely that costs will go up in future. The aim right now is to get us all dependent on the technology, so that we have to keep paying in future (another reason I think its improtant our own countries develop these capaibilites, and that we also need to strive to be capable to work in AI free ways as well. )

## API security

- Managing API keys and credentials
- Sanitizing inputs to remove sensitive information
- Local vs. cloud-based LLM solutions
- Auditing and monitoring LLM interactions



## Agent security 

- Can run code on your computer
- Be careful what it is doing
- Read prompts before running them 

Computer enginners, thinking probabilistically 

## Lethal trifecta for prompt injection attacks

The [Lethal Trifecta for prompt injection attacks](https://simonwillison.net/2025/Aug/9/bay-area-ai/) (coined by Simon Williamson) is access to private data, ability to communicate externally and exposure to untrusted content. 

What can happen is that if your agent can read untrusted sources, those sources may contain malicious prompts. These prompts could convince the agent to do things like send or post your personal data to the hacker or create malicious code that runs on your computer. 

You want to be sure your agents can't do these three things at once. Remember sensitive data includes your name, username, phone number, email, API keys as well as sensitive research data. 